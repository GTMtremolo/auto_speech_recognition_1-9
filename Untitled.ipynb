{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from python_speech_features import mfcc, logfbank,delta\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile as wav\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense, Activation, Dropout\n",
    "from keras.utils import to_categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data_speech_commands/test_data_1_9.txt', sep=\" \", header=None)\n",
    "raw_data = np.asarray(data)\n",
    "target = []\n",
    "for d in data[0]:\n",
    "    target.append(d.split('/')[0])\n",
    "y_test = np.asarray(target)\n",
    "\n",
    "x_test = np.zeros((len(raw_data),99,26))\n",
    "for i in range(len(raw_data)):\n",
    "    (rate,sig) = wav.read(\"data_speech_commands/\"+raw_data[i][0])\n",
    "    mfcc_feat = mfcc(sig,rate, numcep=26 )\n",
    "    mfcc_feat = delta(mfcc_feat, 2)\n",
    "    \n",
    "    while True:\n",
    "        if len(mfcc_feat) == 99:\n",
    "            break\n",
    "        mfcc_feat = np.append(mfcc_feat, np.zeros((1,26)),axis=0)\n",
    "    x_test[i] = mfcc_feat\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3259, 99, 26)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i] == 'one':\n",
    "        y_test[i] = 1\n",
    "    if y_test[i] == 'two':\n",
    "        y_test[i] = 2\n",
    "    if y_test[i] == 'three':\n",
    "        y_test[i] = 3\n",
    "    if y_test[i] == 'four':\n",
    "        y_test[i] = 4\n",
    "    if y_test[i] == 'five':\n",
    "        y_test[i] = 5\n",
    "    if y_test[i] == 'six':\n",
    "        y_test[i] = 6\n",
    "    if y_test[i] == 'seven':\n",
    "        y_test[i] = 7\n",
    "    if y_test[i] == 'eight':\n",
    "        y_test[i] = 8\n",
    "    if y_test[i] == 'nine':\n",
    "        y_test[i] = 9\n",
    "y_test= y_test.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data_speech_commands/train_data_1_9.txt', sep=\" \", header=None)\n",
    "raw_data = np.asarray(data)\n",
    "target = []\n",
    "for d in data[0]:\n",
    "    target.append(d.split('/')[0])\n",
    "    \n",
    "y_train = np.asarray(target)\n",
    "\n",
    "x_train = np.zeros((len(raw_data),99,26))\n",
    "for i in range(len(raw_data)):\n",
    "    (rate,sig) = wav.read(\"data_speech_commands/\"+raw_data[i][0])\n",
    "    mfcc_feat = mfcc(sig,rate,numcep= 26)\n",
    "    mfcc_feat = delta(mfcc_feat, 2)\n",
    "    while True:\n",
    "        if len(mfcc_feat) == 99:\n",
    "            break\n",
    "        mfcc_feat = np.append(mfcc_feat, np.zeros((1,26)),axis=0)\n",
    "    x_train[i] = mfcc_feat\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_train)):\n",
    "    if y_train[i] == 'one':\n",
    "        y_train[i] = 1\n",
    "    if y_train[i] == 'two':\n",
    "        y_train[i] = 2\n",
    "    if y_train[i] == 'three':\n",
    "        y_train[i] = 3\n",
    "    if y_train[i] == 'four':\n",
    "        y_train[i] = 4\n",
    "    if y_train[i] == 'five':\n",
    "        y_train[i] = 5\n",
    "    if y_train[i] == 'six':\n",
    "        y_train[i] = 6\n",
    "    if y_train[i] == 'seven':\n",
    "        y_train[i] = 7\n",
    "    if y_train[i] == 'eight':\n",
    "        y_train[i] = 8\n",
    "    if y_train[i] == 'nine':\n",
    "        y_train[i] = 9\n",
    "y_train= y_train.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3259, 99, 26) (3259,) (3689, 99, 26) (3689, 10)\n"
     ]
    }
   ],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "Y_test = to_categorical(y_test)\n",
    "print(x_test.shape, y_test.shape, x_train.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(y_test[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/giangtm/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/giangtm/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 26)                5512      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 26)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               3456      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 10,258\n",
      "Trainable params: 10,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=26,input_shape=x_train.shape[1:], activation='tanh', recurrent_activation='sigmoid'))\n",
    "model.add(Dropout(0.30))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.30))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/giangtm/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3689 samples, validate on 3259 samples\n",
      "Epoch 1/700\n",
      "3689/3689 [==============================] - 3s 843us/step - loss: 2.3166 - acc: 0.1036 - val_loss: 2.2765 - val_acc: 0.1313\n",
      "Epoch 2/700\n",
      "3689/3689 [==============================] - 2s 455us/step - loss: 2.2604 - acc: 0.1328 - val_loss: 2.2468 - val_acc: 0.1338\n",
      "Epoch 3/700\n",
      "3689/3689 [==============================] - 2s 474us/step - loss: 2.2279 - acc: 0.1510 - val_loss: 2.2251 - val_acc: 0.1393\n",
      "Epoch 4/700\n",
      "3689/3689 [==============================] - 2s 472us/step - loss: 2.2015 - acc: 0.1564 - val_loss: 2.2078 - val_acc: 0.1387\n",
      "Epoch 5/700\n",
      "3689/3689 [==============================] - 2s 480us/step - loss: 2.1839 - acc: 0.1599 - val_loss: 2.1926 - val_acc: 0.1470\n",
      "Epoch 6/700\n",
      "3689/3689 [==============================] - 2s 539us/step - loss: 2.1636 - acc: 0.1762 - val_loss: 2.1763 - val_acc: 0.1614\n",
      "Epoch 7/700\n",
      "3689/3689 [==============================] - 2s 478us/step - loss: 2.1489 - acc: 0.1876 - val_loss: 2.1575 - val_acc: 0.1731\n",
      "Epoch 8/700\n",
      "3689/3689 [==============================] - 2s 534us/step - loss: 2.1115 - acc: 0.2001 - val_loss: 2.1237 - val_acc: 0.1869\n",
      "Epoch 9/700\n",
      "3689/3689 [==============================] - 2s 549us/step - loss: 2.0757 - acc: 0.2310 - val_loss: 2.0540 - val_acc: 0.2283\n",
      "Epoch 10/700\n",
      "3689/3689 [==============================] - 2s 606us/step - loss: 1.9992 - acc: 0.2589 - val_loss: 1.9800 - val_acc: 0.2611\n",
      "Epoch 11/700\n",
      "3689/3689 [==============================] - 2s 546us/step - loss: 1.9380 - acc: 0.2792 - val_loss: 1.9389 - val_acc: 0.2915\n",
      "Epoch 12/700\n",
      "3689/3689 [==============================] - 2s 447us/step - loss: 1.9115 - acc: 0.2914 - val_loss: 1.9228 - val_acc: 0.2811\n",
      "Epoch 13/700\n",
      "3689/3689 [==============================] - 2s 421us/step - loss: 1.8895 - acc: 0.2789 - val_loss: 1.8926 - val_acc: 0.2936\n",
      "Epoch 14/700\n",
      "3689/3689 [==============================] - 2s 422us/step - loss: 1.8490 - acc: 0.3161 - val_loss: 1.8575 - val_acc: 0.3081\n",
      "Epoch 15/700\n",
      "3689/3689 [==============================] - 2s 414us/step - loss: 1.8044 - acc: 0.3229 - val_loss: 1.8330 - val_acc: 0.3127\n",
      "Epoch 16/700\n",
      "3689/3689 [==============================] - 2s 435us/step - loss: 1.7890 - acc: 0.3443 - val_loss: 1.8204 - val_acc: 0.3234\n",
      "Epoch 17/700\n",
      "3689/3689 [==============================] - 2s 418us/step - loss: 1.7629 - acc: 0.3413 - val_loss: 1.8340 - val_acc: 0.3170\n",
      "Epoch 18/700\n",
      "3689/3689 [==============================] - 2s 431us/step - loss: 1.7809 - acc: 0.3310 - val_loss: 1.8337 - val_acc: 0.3240\n",
      "Epoch 19/700\n",
      "3689/3689 [==============================] - 2s 514us/step - loss: 1.7309 - acc: 0.3521 - val_loss: 1.7719 - val_acc: 0.3501\n",
      "Epoch 20/700\n",
      "3689/3689 [==============================] - 2s 471us/step - loss: 1.6974 - acc: 0.3689 - val_loss: 1.7596 - val_acc: 0.3556\n",
      "Epoch 21/700\n",
      "3689/3689 [==============================] - 2s 546us/step - loss: 1.6545 - acc: 0.3868 - val_loss: 1.7243 - val_acc: 0.3780\n",
      "Epoch 22/700\n",
      "3689/3689 [==============================] - 2s 433us/step - loss: 1.6259 - acc: 0.4028 - val_loss: 1.6993 - val_acc: 0.3875\n",
      "Epoch 23/700\n",
      "3689/3689 [==============================] - 2s 435us/step - loss: 1.5979 - acc: 0.4115 - val_loss: 1.6732 - val_acc: 0.4023\n",
      "Epoch 24/700\n",
      "3689/3689 [==============================] - 2s 434us/step - loss: 1.5484 - acc: 0.4375 - val_loss: 1.6644 - val_acc: 0.4004\n",
      "Epoch 25/700\n",
      "3689/3689 [==============================] - 2s 425us/step - loss: 1.5409 - acc: 0.4383 - val_loss: 1.6454 - val_acc: 0.4158\n",
      "Epoch 26/700\n",
      "3689/3689 [==============================] - 2s 443us/step - loss: 1.5046 - acc: 0.4660 - val_loss: 1.6183 - val_acc: 0.4256\n",
      "Epoch 27/700\n",
      "3689/3689 [==============================] - 2s 509us/step - loss: 1.4740 - acc: 0.4714 - val_loss: 1.5684 - val_acc: 0.4412\n",
      "Epoch 28/700\n",
      "3689/3689 [==============================] - 2s 449us/step - loss: 1.4620 - acc: 0.4793 - val_loss: 1.5524 - val_acc: 0.4606\n",
      "Epoch 29/700\n",
      "3689/3689 [==============================] - 2s 467us/step - loss: 1.4162 - acc: 0.5047 - val_loss: 1.5075 - val_acc: 0.4735\n",
      "Epoch 30/700\n",
      "3689/3689 [==============================] - 2s 595us/step - loss: 1.3923 - acc: 0.5123 - val_loss: 1.6129 - val_acc: 0.4296\n",
      "Epoch 31/700\n",
      "3689/3689 [==============================] - 2s 449us/step - loss: 1.4413 - acc: 0.4939 - val_loss: 1.5184 - val_acc: 0.4676\n",
      "Epoch 32/700\n",
      "3689/3689 [==============================] - 3s 699us/step - loss: 1.3624 - acc: 0.5270 - val_loss: 1.4737 - val_acc: 0.4805\n",
      "Epoch 33/700\n",
      "3689/3689 [==============================] - 2s 446us/step - loss: 1.3118 - acc: 0.5462 - val_loss: 1.4497 - val_acc: 0.4943\n",
      "Epoch 34/700\n",
      "3689/3689 [==============================] - 2s 448us/step - loss: 1.2875 - acc: 0.5492 - val_loss: 1.4263 - val_acc: 0.5143\n",
      "Epoch 35/700\n",
      "3689/3689 [==============================] - 2s 423us/step - loss: 1.2627 - acc: 0.5660 - val_loss: 1.4022 - val_acc: 0.5232\n",
      "Epoch 36/700\n",
      "3689/3689 [==============================] - 2s 426us/step - loss: 1.2120 - acc: 0.5907 - val_loss: 1.3858 - val_acc: 0.5330\n",
      "Epoch 37/700\n",
      "3689/3689 [==============================] - 2s 422us/step - loss: 1.1958 - acc: 0.5942 - val_loss: 1.3775 - val_acc: 0.5465\n",
      "Epoch 38/700\n",
      "3689/3689 [==============================] - 2s 421us/step - loss: 1.1689 - acc: 0.6026 - val_loss: 1.3680 - val_acc: 0.5499\n",
      "Epoch 39/700\n",
      "3689/3689 [==============================] - 2s 450us/step - loss: 1.1366 - acc: 0.6162 - val_loss: 1.3488 - val_acc: 0.5535\n",
      "Epoch 40/700\n",
      "3689/3689 [==============================] - 2s 505us/step - loss: 1.1621 - acc: 0.6031 - val_loss: 1.3488 - val_acc: 0.5517\n",
      "Epoch 41/700\n",
      "3689/3689 [==============================] - 2s 533us/step - loss: 1.1102 - acc: 0.6294 - val_loss: 1.3248 - val_acc: 0.5683\n",
      "Epoch 42/700\n",
      "3689/3689 [==============================] - 2s 430us/step - loss: 1.0838 - acc: 0.6389 - val_loss: 1.3088 - val_acc: 0.5747\n",
      "Epoch 43/700\n",
      "3689/3689 [==============================] - 2s 424us/step - loss: 1.0444 - acc: 0.6576 - val_loss: 1.3181 - val_acc: 0.5738\n",
      "Epoch 44/700\n",
      "3689/3689 [==============================] - 2s 426us/step - loss: 1.0341 - acc: 0.6595 - val_loss: 1.3143 - val_acc: 0.5759\n",
      "Epoch 45/700\n",
      "3689/3689 [==============================] - 2s 427us/step - loss: 1.0750 - acc: 0.6365 - val_loss: 1.2980 - val_acc: 0.5781\n",
      "Epoch 46/700\n",
      "3689/3689 [==============================] - 2s 429us/step - loss: 1.0136 - acc: 0.6744 - val_loss: 1.2841 - val_acc: 0.5901\n",
      "Epoch 47/700\n",
      "3689/3689 [==============================] - 2s 424us/step - loss: 1.0070 - acc: 0.6715 - val_loss: 1.2638 - val_acc: 0.5934\n",
      "Epoch 48/700\n",
      "3689/3689 [==============================] - 2s 428us/step - loss: 0.9921 - acc: 0.6736 - val_loss: 1.2354 - val_acc: 0.5944\n",
      "Epoch 49/700\n",
      "3689/3689 [==============================] - 2s 425us/step - loss: 0.9807 - acc: 0.6812 - val_loss: 1.2471 - val_acc: 0.5971\n",
      "Epoch 50/700\n",
      "3689/3689 [==============================] - 2s 432us/step - loss: 0.9452 - acc: 0.6885 - val_loss: 1.2390 - val_acc: 0.6066\n",
      "Epoch 51/700\n",
      "3689/3689 [==============================] - 2s 426us/step - loss: 0.9314 - acc: 0.7005 - val_loss: 1.2281 - val_acc: 0.6088\n",
      "Epoch 52/700\n",
      "3689/3689 [==============================] - 2s 421us/step - loss: 0.8984 - acc: 0.7118 - val_loss: 1.2249 - val_acc: 0.6097\n",
      "Epoch 53/700\n",
      "3689/3689 [==============================] - 2s 420us/step - loss: 0.8983 - acc: 0.7148 - val_loss: 1.2142 - val_acc: 0.6183\n",
      "Epoch 54/700\n",
      "3689/3689 [==============================] - 2s 420us/step - loss: 0.8749 - acc: 0.7205 - val_loss: 1.2093 - val_acc: 0.6226\n",
      "Epoch 55/700\n",
      "3689/3689 [==============================] - 2s 461us/step - loss: 0.8624 - acc: 0.7235 - val_loss: 1.2011 - val_acc: 0.6164\n",
      "Epoch 56/700\n",
      "3689/3689 [==============================] - 2s 425us/step - loss: 0.8361 - acc: 0.7265 - val_loss: 1.1996 - val_acc: 0.6174\n",
      "Epoch 57/700\n",
      "3689/3689 [==============================] - 2s 578us/step - loss: 0.8405 - acc: 0.7297 - val_loss: 1.1967 - val_acc: 0.6257\n",
      "Epoch 58/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3689/3689 [==============================] - 2s 425us/step - loss: 0.8275 - acc: 0.7322 - val_loss: 1.1958 - val_acc: 0.6324\n",
      "Epoch 59/700\n",
      "3689/3689 [==============================] - 2s 416us/step - loss: 0.8002 - acc: 0.7411 - val_loss: 1.1831 - val_acc: 0.6404\n",
      "Epoch 60/700\n",
      "3689/3689 [==============================] - 2s 416us/step - loss: 0.7687 - acc: 0.7506 - val_loss: 1.1845 - val_acc: 0.6388\n",
      "Epoch 61/700\n",
      "3689/3689 [==============================] - 2s 416us/step - loss: 0.7721 - acc: 0.7525 - val_loss: 1.1840 - val_acc: 0.6346\n",
      "Epoch 62/700\n",
      "3689/3689 [==============================] - 2s 419us/step - loss: 0.7899 - acc: 0.7352 - val_loss: 1.1723 - val_acc: 0.6444\n",
      "Epoch 63/700\n",
      "3689/3689 [==============================] - 2s 418us/step - loss: 0.7696 - acc: 0.7503 - val_loss: 1.1587 - val_acc: 0.6462\n",
      "Epoch 64/700\n",
      "3689/3689 [==============================] - 2s 418us/step - loss: 0.7551 - acc: 0.7617 - val_loss: 1.1835 - val_acc: 0.6450\n",
      "Epoch 65/700\n",
      "3689/3689 [==============================] - 2s 415us/step - loss: 0.8024 - acc: 0.7417 - val_loss: 1.1750 - val_acc: 0.6465\n",
      "Epoch 66/700\n",
      "3689/3689 [==============================] - 2s 428us/step - loss: 0.7613 - acc: 0.7544 - val_loss: 1.1577 - val_acc: 0.6499\n",
      "Epoch 67/700\n",
      "3689/3689 [==============================] - 2s 421us/step - loss: 0.7664 - acc: 0.7636 - val_loss: 1.1757 - val_acc: 0.6484\n",
      "Epoch 68/700\n",
      "3689/3689 [==============================] - 2s 422us/step - loss: 0.7447 - acc: 0.7715 - val_loss: 1.1592 - val_acc: 0.6527\n",
      "Epoch 69/700\n",
      "3689/3689 [==============================] - 2s 417us/step - loss: 0.7279 - acc: 0.7758 - val_loss: 1.1547 - val_acc: 0.6600\n",
      "Epoch 70/700\n",
      "3689/3689 [==============================] - 2s 418us/step - loss: 0.7122 - acc: 0.7799 - val_loss: 1.1218 - val_acc: 0.6677\n",
      "Epoch 71/700\n",
      "3689/3689 [==============================] - 2s 429us/step - loss: 0.6905 - acc: 0.7812 - val_loss: 1.1626 - val_acc: 0.6496\n",
      "Epoch 72/700\n",
      "3689/3689 [==============================] - 2s 423us/step - loss: 0.7492 - acc: 0.7577 - val_loss: 1.1420 - val_acc: 0.6628\n",
      "Epoch 73/700\n",
      "3689/3689 [==============================] - 2s 421us/step - loss: 0.6784 - acc: 0.7915 - val_loss: 1.1387 - val_acc: 0.6655\n",
      "Epoch 74/700\n",
      "3689/3689 [==============================] - 2s 423us/step - loss: 0.6868 - acc: 0.7799 - val_loss: 1.1417 - val_acc: 0.6658\n",
      "Epoch 75/700\n",
      "3689/3689 [==============================] - 2s 419us/step - loss: 0.6763 - acc: 0.7910 - val_loss: 1.1413 - val_acc: 0.6631\n",
      "Epoch 76/700\n",
      "3689/3689 [==============================] - 2s 421us/step - loss: 0.6644 - acc: 0.7856 - val_loss: 1.1341 - val_acc: 0.6741\n",
      "Epoch 77/700\n",
      "3689/3689 [==============================] - 2s 443us/step - loss: 0.6191 - acc: 0.8062 - val_loss: 1.1410 - val_acc: 0.6772\n",
      "Epoch 78/700\n",
      "3689/3689 [==============================] - 2s 458us/step - loss: 0.6014 - acc: 0.8116 - val_loss: 1.1373 - val_acc: 0.6800\n",
      "Epoch 79/700\n",
      "3689/3689 [==============================] - 2s 422us/step - loss: 0.6099 - acc: 0.8116 - val_loss: 1.1366 - val_acc: 0.6787\n",
      "Epoch 80/700\n",
      "3689/3689 [==============================] - 2s 421us/step - loss: 0.6135 - acc: 0.8040 - val_loss: 1.1306 - val_acc: 0.6830\n",
      "Epoch 81/700\n",
      "3689/3689 [==============================] - 2s 426us/step - loss: 0.5902 - acc: 0.8192 - val_loss: 1.1307 - val_acc: 0.6916\n",
      "Epoch 82/700\n",
      "3689/3689 [==============================] - 2s 418us/step - loss: 0.5698 - acc: 0.8268 - val_loss: 1.1274 - val_acc: 0.6916\n",
      "Epoch 83/700\n",
      "3689/3689 [==============================] - 2s 418us/step - loss: 0.5946 - acc: 0.8241 - val_loss: 1.1598 - val_acc: 0.6916\n",
      "Epoch 84/700\n",
      "3689/3689 [==============================] - 2s 418us/step - loss: 0.5891 - acc: 0.8211 - val_loss: 1.1002 - val_acc: 0.6932\n",
      "Epoch 85/700\n",
      "3689/3689 [==============================] - 2s 421us/step - loss: 0.5626 - acc: 0.8273 - val_loss: 1.1461 - val_acc: 0.6907\n",
      "Epoch 86/700\n",
      "3689/3689 [==============================] - 2s 417us/step - loss: 0.6895 - acc: 0.7964 - val_loss: 1.1392 - val_acc: 0.6867\n",
      "Epoch 87/700\n",
      "3689/3689 [==============================] - 2s 440us/step - loss: 0.6474 - acc: 0.8067 - val_loss: 1.1201 - val_acc: 0.6803\n",
      "Epoch 88/700\n",
      "3689/3689 [==============================] - 2s 474us/step - loss: 0.6397 - acc: 0.8032 - val_loss: 1.0729 - val_acc: 0.6981\n",
      "Epoch 89/700\n",
      "3689/3689 [==============================] - 2s 506us/step - loss: 0.6088 - acc: 0.8184 - val_loss: 1.0642 - val_acc: 0.6981\n",
      "Epoch 90/700\n",
      "3689/3689 [==============================] - 2s 549us/step - loss: 0.5719 - acc: 0.8276 - val_loss: 1.0801 - val_acc: 0.6987\n",
      "Epoch 91/700\n",
      "3689/3689 [==============================] - 2s 675us/step - loss: 0.5532 - acc: 0.8322 - val_loss: 1.0753 - val_acc: 0.7027\n",
      "Epoch 92/700\n",
      "3689/3689 [==============================] - 2s 633us/step - loss: 0.5234 - acc: 0.8422 - val_loss: 1.0887 - val_acc: 0.7024\n",
      "Epoch 93/700\n",
      "3689/3689 [==============================] - 3s 683us/step - loss: 0.5211 - acc: 0.8398 - val_loss: 1.0986 - val_acc: 0.7054\n",
      "Epoch 94/700\n",
      "3689/3689 [==============================] - 2s 671us/step - loss: 0.5125 - acc: 0.8466 - val_loss: 1.0848 - val_acc: 0.7094\n",
      "Epoch 95/700\n",
      "3689/3689 [==============================] - 2s 595us/step - loss: 0.5240 - acc: 0.8422 - val_loss: 1.0862 - val_acc: 0.7125\n",
      "Epoch 96/700\n",
      "3689/3689 [==============================] - 2s 591us/step - loss: 0.4986 - acc: 0.8425 - val_loss: 1.1064 - val_acc: 0.7146\n",
      "Epoch 97/700\n",
      "3689/3689 [==============================] - 2s 596us/step - loss: 0.4957 - acc: 0.8466 - val_loss: 1.0807 - val_acc: 0.7149\n",
      "Epoch 98/700\n",
      "3689/3689 [==============================] - 2s 591us/step - loss: 0.4960 - acc: 0.8466 - val_loss: 1.0906 - val_acc: 0.7140\n",
      "Epoch 99/700\n",
      "3689/3689 [==============================] - 2s 628us/step - loss: 0.4777 - acc: 0.8590 - val_loss: 1.0973 - val_acc: 0.7159\n",
      "Epoch 100/700\n",
      "3689/3689 [==============================] - 2s 582us/step - loss: 0.5065 - acc: 0.8523 - val_loss: 1.0946 - val_acc: 0.7153\n",
      "Epoch 101/700\n",
      "3689/3689 [==============================] - 2s 601us/step - loss: 0.4729 - acc: 0.8569 - val_loss: 1.0625 - val_acc: 0.7177\n",
      "Epoch 102/700\n",
      "3689/3689 [==============================] - 2s 670us/step - loss: 0.4592 - acc: 0.8609 - val_loss: 1.0770 - val_acc: 0.7238\n",
      "Epoch 103/700\n",
      "3689/3689 [==============================] - 3s 700us/step - loss: 0.4543 - acc: 0.8636 - val_loss: 1.0928 - val_acc: 0.7159\n",
      "Epoch 104/700\n",
      "3689/3689 [==============================] - 3s 681us/step - loss: 0.4665 - acc: 0.8571 - val_loss: 1.0961 - val_acc: 0.7202\n",
      "Epoch 105/700\n",
      "3689/3689 [==============================] - 2s 622us/step - loss: 0.4647 - acc: 0.8582 - val_loss: 1.1906 - val_acc: 0.7054\n",
      "Epoch 106/700\n",
      "3689/3689 [==============================] - 2s 635us/step - loss: 0.6155 - acc: 0.8214 - val_loss: 1.1064 - val_acc: 0.7070\n",
      "Epoch 107/700\n",
      "3689/3689 [==============================] - 2s 616us/step - loss: 0.5486 - acc: 0.8333 - val_loss: 1.0673 - val_acc: 0.7199\n",
      "Epoch 108/700\n",
      "3689/3689 [==============================] - 3s 779us/step - loss: 0.5053 - acc: 0.8411 - val_loss: 1.0169 - val_acc: 0.7284\n",
      "Epoch 109/700\n",
      "3689/3689 [==============================] - 3s 704us/step - loss: 0.4709 - acc: 0.8571 - val_loss: 1.0087 - val_acc: 0.7343\n",
      "Epoch 110/700\n",
      "3689/3689 [==============================] - 2s 545us/step - loss: 0.4631 - acc: 0.8582 - val_loss: 1.0435 - val_acc: 0.7312\n",
      "Epoch 111/700\n",
      "3689/3689 [==============================] - 2s 532us/step - loss: 0.4661 - acc: 0.8577 - val_loss: 1.0364 - val_acc: 0.7349\n",
      "Epoch 112/700\n",
      "3689/3689 [==============================] - 2s 623us/step - loss: 0.4350 - acc: 0.8707 - val_loss: 1.0499 - val_acc: 0.7324\n",
      "Epoch 113/700\n",
      "3689/3689 [==============================] - 2s 515us/step - loss: 0.4226 - acc: 0.8677 - val_loss: 1.0532 - val_acc: 0.7386\n",
      "Epoch 114/700\n",
      "3689/3689 [==============================] - 2s 450us/step - loss: 0.4064 - acc: 0.8791 - val_loss: 1.0647 - val_acc: 0.7370\n",
      "Epoch 115/700\n",
      "3689/3689 [==============================] - 2s 614us/step - loss: 0.5405 - acc: 0.8395 - val_loss: 1.2117 - val_acc: 0.7106\n",
      "Epoch 116/700\n",
      "3689/3689 [==============================] - 2s 427us/step - loss: 0.5059 - acc: 0.8485 - val_loss: 1.0342 - val_acc: 0.7266\n",
      "Epoch 117/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3689/3689 [==============================] - 2s 420us/step - loss: 0.4560 - acc: 0.8650 - val_loss: 1.0623 - val_acc: 0.7370\n",
      "Epoch 118/700\n",
      "3689/3689 [==============================] - 2s 478us/step - loss: 0.4705 - acc: 0.8577 - val_loss: 1.0316 - val_acc: 0.7373\n",
      "Epoch 119/700\n",
      "3689/3689 [==============================] - 2s 420us/step - loss: 0.4658 - acc: 0.8574 - val_loss: 1.0589 - val_acc: 0.7269\n",
      "Epoch 120/700\n",
      "3689/3689 [==============================] - 2s 430us/step - loss: 0.4424 - acc: 0.8664 - val_loss: 1.0371 - val_acc: 0.7386\n",
      "Epoch 121/700\n",
      "3689/3689 [==============================] - 2s 469us/step - loss: 0.4269 - acc: 0.8677 - val_loss: 1.0515 - val_acc: 0.7361\n",
      "Epoch 122/700\n",
      "3689/3689 [==============================] - 2s 427us/step - loss: 0.4370 - acc: 0.8683 - val_loss: 1.0188 - val_acc: 0.7429\n",
      "Epoch 123/700\n",
      "3689/3689 [==============================] - 2s 478us/step - loss: 0.3786 - acc: 0.8834 - val_loss: 1.0319 - val_acc: 0.7465\n",
      "Epoch 124/700\n",
      "3689/3689 [==============================] - 2s 435us/step - loss: 0.3723 - acc: 0.8935 - val_loss: 1.0490 - val_acc: 0.7484\n",
      "Epoch 125/700\n",
      "3689/3689 [==============================] - 2s 430us/step - loss: 0.4311 - acc: 0.8750 - val_loss: 1.0376 - val_acc: 0.7447\n",
      "Epoch 126/700\n",
      "3689/3689 [==============================] - 2s 438us/step - loss: 0.4117 - acc: 0.8726 - val_loss: 1.0121 - val_acc: 0.7456\n",
      "Epoch 127/700\n",
      "3689/3689 [==============================] - 2s 449us/step - loss: 0.4344 - acc: 0.8791 - val_loss: 1.0016 - val_acc: 0.7447\n",
      "Epoch 128/700\n",
      "3689/3689 [==============================] - 2s 439us/step - loss: 0.3854 - acc: 0.8856 - val_loss: 1.0083 - val_acc: 0.7493\n",
      "Epoch 129/700\n",
      "3689/3689 [==============================] - 2s 431us/step - loss: 0.3690 - acc: 0.8861 - val_loss: 1.0218 - val_acc: 0.7515\n",
      "Epoch 130/700\n",
      "3689/3689 [==============================] - 2s 465us/step - loss: 0.3795 - acc: 0.8853 - val_loss: 1.0303 - val_acc: 0.7435\n",
      "Epoch 131/700\n",
      "3689/3689 [==============================] - 2s 459us/step - loss: 0.3535 - acc: 0.8940 - val_loss: 1.0118 - val_acc: 0.7487\n",
      "Epoch 132/700\n",
      "3689/3689 [==============================] - 2s 458us/step - loss: 0.3363 - acc: 0.8946 - val_loss: 1.0469 - val_acc: 0.7493\n",
      "Epoch 133/700\n",
      "3689/3689 [==============================] - 2s 420us/step - loss: 0.3283 - acc: 0.9008 - val_loss: 1.0441 - val_acc: 0.7502\n",
      "Epoch 134/700\n",
      "3689/3689 [==============================] - 2s 436us/step - loss: 0.3518 - acc: 0.8943 - val_loss: 0.9981 - val_acc: 0.7533\n",
      "Epoch 135/700\n",
      "3689/3689 [==============================] - 2s 431us/step - loss: 0.3578 - acc: 0.8905 - val_loss: 1.0220 - val_acc: 0.7496\n",
      "Epoch 136/700\n",
      "3689/3689 [==============================] - 2s 435us/step - loss: 0.3227 - acc: 0.8978 - val_loss: 1.0495 - val_acc: 0.7548\n",
      "Epoch 137/700\n",
      "3689/3689 [==============================] - 2s 454us/step - loss: 0.3137 - acc: 0.9105 - val_loss: 1.0426 - val_acc: 0.7505\n",
      "Epoch 138/700\n",
      "3689/3689 [==============================] - 2s 425us/step - loss: 0.3144 - acc: 0.9016 - val_loss: 1.0536 - val_acc: 0.7542\n",
      "Epoch 139/700\n",
      "3689/3689 [==============================] - 2s 427us/step - loss: 0.2966 - acc: 0.9105 - val_loss: 1.0583 - val_acc: 0.7579\n",
      "Epoch 140/700\n",
      "3689/3689 [==============================] - 2s 507us/step - loss: 0.2938 - acc: 0.9127 - val_loss: 1.0835 - val_acc: 0.7515\n",
      "Epoch 141/700\n",
      "3689/3689 [==============================] - 2s 525us/step - loss: 0.2979 - acc: 0.9116 - val_loss: 1.0633 - val_acc: 0.7604\n",
      "Epoch 142/700\n",
      "3689/3689 [==============================] - 2s 493us/step - loss: 0.2895 - acc: 0.9114 - val_loss: 1.0596 - val_acc: 0.7597\n",
      "Epoch 143/700\n",
      "3689/3689 [==============================] - 2s 488us/step - loss: 0.2809 - acc: 0.9143 - val_loss: 1.0887 - val_acc: 0.7576\n",
      "Epoch 144/700\n",
      "3689/3689 [==============================] - 2s 612us/step - loss: 0.2905 - acc: 0.9114 - val_loss: 1.0867 - val_acc: 0.7576\n",
      "Epoch 145/700\n",
      "3689/3689 [==============================] - 2s 631us/step - loss: 0.3058 - acc: 0.9097 - val_loss: 1.0824 - val_acc: 0.7570\n",
      "Epoch 146/700\n",
      "3689/3689 [==============================] - 2s 626us/step - loss: 0.3136 - acc: 0.9105 - val_loss: 1.0576 - val_acc: 0.7650\n",
      "Epoch 147/700\n",
      "3689/3689 [==============================] - 2s 646us/step - loss: 0.3069 - acc: 0.9135 - val_loss: 1.0794 - val_acc: 0.7594\n",
      "Epoch 148/700\n",
      "3689/3689 [==============================] - 2s 580us/step - loss: 0.3000 - acc: 0.9078 - val_loss: 1.0944 - val_acc: 0.7613\n",
      "Epoch 149/700\n",
      "3689/3689 [==============================] - 2s 586us/step - loss: 0.2865 - acc: 0.9162 - val_loss: 1.0541 - val_acc: 0.7662\n",
      "Epoch 150/700\n",
      "3689/3689 [==============================] - 2s 583us/step - loss: 0.2748 - acc: 0.9208 - val_loss: 1.0796 - val_acc: 0.7653\n",
      "Epoch 151/700\n",
      "3689/3689 [==============================] - 3s 836us/step - loss: 0.2754 - acc: 0.9176 - val_loss: 1.1020 - val_acc: 0.7637\n",
      "Epoch 152/700\n",
      "3689/3689 [==============================] - 2s 509us/step - loss: 0.2636 - acc: 0.9206 - val_loss: 1.0754 - val_acc: 0.7656\n",
      "Epoch 153/700\n",
      "3689/3689 [==============================] - 2s 613us/step - loss: 0.2635 - acc: 0.9200 - val_loss: 1.1298 - val_acc: 0.7628\n",
      "Epoch 154/700\n",
      "3689/3689 [==============================] - 2s 576us/step - loss: 0.6179 - acc: 0.8271 - val_loss: 1.1678 - val_acc: 0.7340\n",
      "Epoch 155/700\n",
      "3689/3689 [==============================] - 2s 598us/step - loss: 0.5067 - acc: 0.8544 - val_loss: 1.0052 - val_acc: 0.7490\n",
      "Epoch 156/700\n",
      "3689/3689 [==============================] - 2s 589us/step - loss: 0.4329 - acc: 0.8674 - val_loss: 0.9898 - val_acc: 0.7588\n",
      "Epoch 157/700\n",
      "3689/3689 [==============================] - 2s 575us/step - loss: 0.4075 - acc: 0.8753 - val_loss: 0.9724 - val_acc: 0.7607\n",
      "Epoch 158/700\n",
      "3689/3689 [==============================] - 2s 591us/step - loss: 0.3678 - acc: 0.8867 - val_loss: 0.9652 - val_acc: 0.7696\n",
      "Epoch 159/700\n",
      "3689/3689 [==============================] - 2s 571us/step - loss: 0.3219 - acc: 0.9002 - val_loss: 0.9769 - val_acc: 0.7714\n",
      "Epoch 160/700\n",
      "3689/3689 [==============================] - 2s 561us/step - loss: 0.2996 - acc: 0.9108 - val_loss: 0.9826 - val_acc: 0.7729\n",
      "Epoch 161/700\n",
      "3689/3689 [==============================] - 2s 592us/step - loss: 0.2835 - acc: 0.9165 - val_loss: 0.9980 - val_acc: 0.7760\n",
      "Epoch 162/700\n",
      "3689/3689 [==============================] - 2s 556us/step - loss: 0.2903 - acc: 0.9084 - val_loss: 1.0305 - val_acc: 0.7778\n",
      "Epoch 163/700\n",
      "3689/3689 [==============================] - 2s 554us/step - loss: 0.2747 - acc: 0.9176 - val_loss: 1.0383 - val_acc: 0.7763\n",
      "Epoch 164/700\n",
      "3689/3689 [==============================] - 2s 566us/step - loss: 0.2688 - acc: 0.9149 - val_loss: 1.0292 - val_acc: 0.7828\n",
      "Epoch 165/700\n",
      "3689/3689 [==============================] - 2s 575us/step - loss: 0.2960 - acc: 0.9100 - val_loss: 1.0395 - val_acc: 0.7754\n",
      "Epoch 166/700\n",
      "3689/3689 [==============================] - 2s 575us/step - loss: 0.3771 - acc: 0.8970 - val_loss: 1.3012 - val_acc: 0.7017\n",
      "Epoch 167/700\n",
      "3689/3689 [==============================] - 2s 621us/step - loss: 0.7329 - acc: 0.7755 - val_loss: 1.0523 - val_acc: 0.7235\n",
      "Epoch 168/700\n",
      "3689/3689 [==============================] - 3s 721us/step - loss: 0.5299 - acc: 0.8322 - val_loss: 0.9659 - val_acc: 0.7524\n",
      "Epoch 169/700\n",
      "3689/3689 [==============================] - 2s 503us/step - loss: 0.4062 - acc: 0.8769 - val_loss: 0.9349 - val_acc: 0.7708\n",
      "Epoch 170/700\n",
      "3689/3689 [==============================] - 2s 523us/step - loss: 0.3610 - acc: 0.8959 - val_loss: 0.9150 - val_acc: 0.7772\n",
      "Epoch 171/700\n",
      "3689/3689 [==============================] - 2s 482us/step - loss: 0.3377 - acc: 0.9051 - val_loss: 0.9272 - val_acc: 0.7828\n",
      "Epoch 172/700\n",
      "3689/3689 [==============================] - 2s 476us/step - loss: 0.5390 - acc: 0.8661 - val_loss: 1.2313 - val_acc: 0.7199\n",
      "Epoch 173/700\n",
      "3689/3689 [==============================] - 2s 487us/step - loss: 0.8023 - acc: 0.7777 - val_loss: 0.9913 - val_acc: 0.7327\n",
      "Epoch 174/700\n",
      "3689/3689 [==============================] - 2s 493us/step - loss: 0.5468 - acc: 0.8425 - val_loss: 0.8954 - val_acc: 0.7576\n",
      "Epoch 175/700\n",
      "3689/3689 [==============================] - 2s 489us/step - loss: 0.4278 - acc: 0.8731 - val_loss: 0.8883 - val_acc: 0.7683\n",
      "Epoch 176/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3689/3689 [==============================] - 2s 534us/step - loss: 0.3811 - acc: 0.8902 - val_loss: 0.8856 - val_acc: 0.7729\n",
      "Epoch 177/700\n",
      "3689/3689 [==============================] - 2s 538us/step - loss: 0.3582 - acc: 0.8951 - val_loss: 0.9071 - val_acc: 0.7739\n",
      "Epoch 178/700\n",
      "3689/3689 [==============================] - 2s 481us/step - loss: 0.3365 - acc: 0.8978 - val_loss: 0.9030 - val_acc: 0.7769\n",
      "Epoch 179/700\n",
      "3689/3689 [==============================] - 2s 489us/step - loss: 0.3169 - acc: 0.9038 - val_loss: 0.9300 - val_acc: 0.7745\n",
      "Epoch 180/700\n",
      "3689/3689 [==============================] - 2s 483us/step - loss: 0.3067 - acc: 0.9105 - val_loss: 0.9284 - val_acc: 0.7745\n",
      "Epoch 181/700\n",
      "3689/3689 [==============================] - 2s 499us/step - loss: 0.3052 - acc: 0.9095 - val_loss: 0.9468 - val_acc: 0.7739\n",
      "Epoch 182/700\n",
      "3689/3689 [==============================] - 2s 533us/step - loss: 0.2872 - acc: 0.9195 - val_loss: 0.9574 - val_acc: 0.7778\n",
      "Epoch 183/700\n",
      "3689/3689 [==============================] - 2s 585us/step - loss: 0.2755 - acc: 0.9217 - val_loss: 0.9536 - val_acc: 0.7837\n",
      "Epoch 184/700\n",
      "3689/3689 [==============================] - 2s 476us/step - loss: 0.2663 - acc: 0.9241 - val_loss: 0.9653 - val_acc: 0.7806\n",
      "Epoch 185/700\n",
      "3689/3689 [==============================] - 2s 538us/step - loss: 0.2669 - acc: 0.9165 - val_loss: 0.9980 - val_acc: 0.7788\n",
      "Epoch 186/700\n",
      "3689/3689 [==============================] - 2s 500us/step - loss: 0.2734 - acc: 0.9203 - val_loss: 0.9987 - val_acc: 0.7794\n",
      "Epoch 187/700\n",
      "3689/3689 [==============================] - 2s 475us/step - loss: 0.2714 - acc: 0.9208 - val_loss: 0.9853 - val_acc: 0.7828\n",
      "Epoch 188/700\n",
      "3689/3689 [==============================] - 2s 487us/step - loss: 0.2728 - acc: 0.9246 - val_loss: 0.9887 - val_acc: 0.7806\n",
      "Epoch 189/700\n",
      "3689/3689 [==============================] - 2s 513us/step - loss: 0.2626 - acc: 0.9246 - val_loss: 1.0050 - val_acc: 0.7831\n",
      "Epoch 190/700\n",
      "3689/3689 [==============================] - 2s 479us/step - loss: 0.2612 - acc: 0.9222 - val_loss: 0.9688 - val_acc: 0.7840\n",
      "Epoch 191/700\n",
      "3689/3689 [==============================] - 2s 487us/step - loss: 0.2808 - acc: 0.9171 - val_loss: 1.0062 - val_acc: 0.7828\n",
      "Epoch 192/700\n",
      "3689/3689 [==============================] - 2s 480us/step - loss: 0.2990 - acc: 0.9108 - val_loss: 1.0365 - val_acc: 0.7772\n",
      "Epoch 193/700\n",
      "3689/3689 [==============================] - 2s 532us/step - loss: 0.2874 - acc: 0.9149 - val_loss: 0.9645 - val_acc: 0.7871\n",
      "Epoch 194/700\n",
      "3689/3689 [==============================] - 2s 485us/step - loss: 0.2609 - acc: 0.9200 - val_loss: 0.9957 - val_acc: 0.7855\n",
      "Epoch 195/700\n",
      "3689/3689 [==============================] - 2s 498us/step - loss: 0.2524 - acc: 0.9257 - val_loss: 0.9866 - val_acc: 0.7834\n",
      "Epoch 196/700\n",
      "3689/3689 [==============================] - 2s 659us/step - loss: 0.2424 - acc: 0.9284 - val_loss: 1.0275 - val_acc: 0.7880\n",
      "Epoch 197/700\n",
      "3689/3689 [==============================] - 2s 566us/step - loss: 0.2935 - acc: 0.9111 - val_loss: 0.9508 - val_acc: 0.7840\n",
      "Epoch 198/700\n",
      "3689/3689 [==============================] - 3s 912us/step - loss: 0.3340 - acc: 0.9046 - val_loss: 0.9952 - val_acc: 0.7686\n",
      "Epoch 199/700\n",
      "3689/3689 [==============================] - 3s 680us/step - loss: 0.3449 - acc: 0.8951 - val_loss: 0.9938 - val_acc: 0.7782\n",
      "Epoch 200/700\n",
      "3689/3689 [==============================] - 3s 746us/step - loss: 0.3091 - acc: 0.9065 - val_loss: 0.9363 - val_acc: 0.7917\n",
      "Epoch 201/700\n",
      "3689/3689 [==============================] - 2s 625us/step - loss: 0.2877 - acc: 0.9152 - val_loss: 0.9480 - val_acc: 0.7913\n",
      "Epoch 202/700\n",
      "3689/3689 [==============================] - 3s 715us/step - loss: 0.2547 - acc: 0.9257 - val_loss: 0.9570 - val_acc: 0.7901\n",
      "Epoch 203/700\n",
      "3689/3689 [==============================] - 2s 658us/step - loss: 0.2592 - acc: 0.9298 - val_loss: 0.9459 - val_acc: 0.7975\n",
      "Epoch 204/700\n",
      "3689/3689 [==============================] - 2s 590us/step - loss: 0.2361 - acc: 0.9282 - val_loss: 0.9348 - val_acc: 0.7981\n",
      "Epoch 205/700\n",
      "3689/3689 [==============================] - 2s 584us/step - loss: 0.2247 - acc: 0.9379 - val_loss: 0.9547 - val_acc: 0.7999\n",
      "Epoch 206/700\n",
      "3689/3689 [==============================] - 2s 629us/step - loss: 0.3923 - acc: 0.8856 - val_loss: 1.2243 - val_acc: 0.6907\n",
      "Epoch 207/700\n",
      "3689/3689 [==============================] - 3s 738us/step - loss: 0.6241 - acc: 0.7918 - val_loss: 1.0660 - val_acc: 0.7180\n",
      "Epoch 208/700\n",
      "3689/3689 [==============================] - 2s 647us/step - loss: 0.5029 - acc: 0.8306 - val_loss: 1.0333 - val_acc: 0.7346\n",
      "Epoch 209/700\n",
      "3689/3689 [==============================] - 2s 666us/step - loss: 0.4464 - acc: 0.8501 - val_loss: 0.9848 - val_acc: 0.7441\n",
      "Epoch 210/700\n",
      "3689/3689 [==============================] - 2s 490us/step - loss: 0.4031 - acc: 0.8704 - val_loss: 0.9799 - val_acc: 0.7582\n",
      "Epoch 211/700\n",
      "3689/3689 [==============================] - 2s 524us/step - loss: 0.3982 - acc: 0.8750 - val_loss: 0.9568 - val_acc: 0.7647\n",
      "Epoch 212/700\n",
      "3689/3689 [==============================] - 2s 556us/step - loss: 0.3398 - acc: 0.8929 - val_loss: 0.9454 - val_acc: 0.7723\n",
      "Epoch 213/700\n",
      "3689/3689 [==============================] - 2s 489us/step - loss: 0.3089 - acc: 0.9062 - val_loss: 0.9495 - val_acc: 0.7800\n",
      "Epoch 214/700\n",
      "3689/3689 [==============================] - 2s 491us/step - loss: 0.2999 - acc: 0.9138 - val_loss: 0.9599 - val_acc: 0.7837\n",
      "Epoch 215/700\n",
      "3689/3689 [==============================] - 2s 559us/step - loss: 0.2767 - acc: 0.9165 - val_loss: 0.9688 - val_acc: 0.7858\n",
      "Epoch 216/700\n",
      "3689/3689 [==============================] - 2s 514us/step - loss: 0.2715 - acc: 0.9217 - val_loss: 0.9592 - val_acc: 0.7846\n",
      "Epoch 217/700\n",
      "3689/3689 [==============================] - 2s 533us/step - loss: 0.2661 - acc: 0.9198 - val_loss: 0.9699 - val_acc: 0.7883\n",
      "Epoch 218/700\n",
      "3689/3689 [==============================] - 2s 507us/step - loss: 0.2519 - acc: 0.9284 - val_loss: 0.9899 - val_acc: 0.7901\n",
      "Epoch 219/700\n",
      "3689/3689 [==============================] - 2s 647us/step - loss: 0.2427 - acc: 0.9233 - val_loss: 0.9775 - val_acc: 0.7907\n",
      "Epoch 220/700\n",
      "3689/3689 [==============================] - 2s 639us/step - loss: 0.2495 - acc: 0.9238 - val_loss: 0.9772 - val_acc: 0.7966\n",
      "Epoch 221/700\n",
      "3689/3689 [==============================] - 2s 538us/step - loss: 0.2522 - acc: 0.9265 - val_loss: 1.0236 - val_acc: 0.7834\n",
      "Epoch 222/700\n",
      "3689/3689 [==============================] - 2s 470us/step - loss: 0.2634 - acc: 0.9149 - val_loss: 0.9837 - val_acc: 0.7895\n",
      "Epoch 223/700\n",
      "3689/3689 [==============================] - 2s 470us/step - loss: 0.2322 - acc: 0.9295 - val_loss: 1.0039 - val_acc: 0.7935\n",
      "Epoch 224/700\n",
      "3689/3689 [==============================] - 2s 467us/step - loss: 0.2155 - acc: 0.9358 - val_loss: 1.0182 - val_acc: 0.7932\n",
      "Epoch 225/700\n",
      "3689/3689 [==============================] - 2s 475us/step - loss: 0.2189 - acc: 0.9363 - val_loss: 1.0263 - val_acc: 0.7920\n",
      "Epoch 226/700\n",
      "3689/3689 [==============================] - 2s 474us/step - loss: 0.2139 - acc: 0.9355 - val_loss: 1.0500 - val_acc: 0.7892\n",
      "Epoch 227/700\n",
      "3689/3689 [==============================] - 2s 466us/step - loss: 0.2050 - acc: 0.9412 - val_loss: 1.0294 - val_acc: 0.7920\n",
      "Epoch 228/700\n",
      "3689/3689 [==============================] - 2s 475us/step - loss: 0.2200 - acc: 0.9317 - val_loss: 1.0802 - val_acc: 0.7886\n",
      "Epoch 229/700\n",
      "3689/3689 [==============================] - 2s 471us/step - loss: 0.2468 - acc: 0.9252 - val_loss: 1.0258 - val_acc: 0.7938\n",
      "Epoch 230/700\n",
      "3689/3689 [==============================] - 2s 492us/step - loss: 0.3410 - acc: 0.9035 - val_loss: 1.0333 - val_acc: 0.7757\n",
      "Epoch 231/700\n",
      "3689/3689 [==============================] - 2s 473us/step - loss: 0.3455 - acc: 0.8986 - val_loss: 1.0131 - val_acc: 0.7855\n",
      "Epoch 232/700\n",
      "3689/3689 [==============================] - 2s 510us/step - loss: 0.2831 - acc: 0.9138 - val_loss: 0.9654 - val_acc: 0.7913\n",
      "Epoch 233/700\n",
      "3689/3689 [==============================] - 2s 565us/step - loss: 0.2438 - acc: 0.9287 - val_loss: 0.9887 - val_acc: 0.7947\n",
      "Epoch 234/700\n",
      "3689/3689 [==============================] - 3s 721us/step - loss: 0.2446 - acc: 0.9260 - val_loss: 0.9588 - val_acc: 0.7987\n",
      "Epoch 235/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3689/3689 [==============================] - 2s 599us/step - loss: 0.2269 - acc: 0.9317 - val_loss: 0.9626 - val_acc: 0.7996\n",
      "Epoch 236/700\n",
      "3689/3689 [==============================] - 2s 468us/step - loss: 0.2127 - acc: 0.9387 - val_loss: 0.9831 - val_acc: 0.7990\n",
      "Epoch 237/700\n",
      "3689/3689 [==============================] - 2s 465us/step - loss: 0.2036 - acc: 0.9371 - val_loss: 0.9865 - val_acc: 0.8015\n",
      "Epoch 238/700\n",
      "3689/3689 [==============================] - 2s 483us/step - loss: 0.2174 - acc: 0.9347 - val_loss: 0.9732 - val_acc: 0.8015\n",
      "Epoch 239/700\n",
      "3689/3689 [==============================] - 2s 474us/step - loss: 0.1917 - acc: 0.9431 - val_loss: 0.9766 - val_acc: 0.8052\n",
      "Epoch 240/700\n",
      "3689/3689 [==============================] - 2s 594us/step - loss: 0.1826 - acc: 0.9423 - val_loss: 0.9853 - val_acc: 0.8064\n",
      "Epoch 241/700\n",
      "3689/3689 [==============================] - 2s 472us/step - loss: 0.1873 - acc: 0.9444 - val_loss: 0.9897 - val_acc: 0.8085\n",
      "Epoch 242/700\n",
      "3689/3689 [==============================] - 2s 471us/step - loss: 0.1814 - acc: 0.9471 - val_loss: 1.0184 - val_acc: 0.8079\n",
      "Epoch 243/700\n",
      "3689/3689 [==============================] - 2s 511us/step - loss: 0.1772 - acc: 0.9469 - val_loss: 1.0187 - val_acc: 0.8067\n",
      "Epoch 244/700\n",
      "3689/3689 [==============================] - 2s 469us/step - loss: 0.1730 - acc: 0.9499 - val_loss: 1.0126 - val_acc: 0.8110\n",
      "Epoch 245/700\n",
      "3689/3689 [==============================] - 2s 468us/step - loss: 0.1675 - acc: 0.9463 - val_loss: 1.0289 - val_acc: 0.8095\n",
      "Epoch 246/700\n",
      "3689/3689 [==============================] - 2s 495us/step - loss: 0.1740 - acc: 0.9450 - val_loss: 1.0320 - val_acc: 0.8079\n",
      "Epoch 247/700\n",
      "3689/3689 [==============================] - 2s 467us/step - loss: 0.1706 - acc: 0.9499 - val_loss: 1.0554 - val_acc: 0.8088\n",
      "Epoch 248/700\n",
      "3689/3689 [==============================] - 2s 473us/step - loss: 0.1779 - acc: 0.9439 - val_loss: 1.0666 - val_acc: 0.8036\n",
      "Epoch 249/700\n",
      "3689/3689 [==============================] - 2s 469us/step - loss: 0.1785 - acc: 0.9461 - val_loss: 1.0559 - val_acc: 0.8042\n",
      "Epoch 250/700\n",
      "3689/3689 [==============================] - 2s 521us/step - loss: 0.1761 - acc: 0.9471 - val_loss: 1.0816 - val_acc: 0.8024\n",
      "Epoch 251/700\n",
      "3689/3689 [==============================] - 2s 542us/step - loss: 0.1993 - acc: 0.9371 - val_loss: 1.0493 - val_acc: 0.8006\n",
      "Epoch 252/700\n",
      "3689/3689 [==============================] - 3s 764us/step - loss: 0.1815 - acc: 0.9452 - val_loss: 1.0583 - val_acc: 0.8052\n",
      "Epoch 253/700\n",
      "3689/3689 [==============================] - 3s 766us/step - loss: 0.1857 - acc: 0.9433 - val_loss: 1.0539 - val_acc: 0.8048\n",
      "Epoch 254/700\n",
      "3689/3689 [==============================] - 3s 730us/step - loss: 0.1752 - acc: 0.9490 - val_loss: 1.0698 - val_acc: 0.8058\n",
      "Epoch 255/700\n",
      "3689/3689 [==============================] - 3s 726us/step - loss: 0.1884 - acc: 0.9461 - val_loss: 1.0948 - val_acc: 0.7987\n",
      "Epoch 256/700\n",
      "3689/3689 [==============================] - 2s 486us/step - loss: 0.1984 - acc: 0.9406 - val_loss: 1.0370 - val_acc: 0.8030\n",
      "Epoch 257/700\n",
      "3689/3689 [==============================] - 2s 465us/step - loss: 0.1931 - acc: 0.9377 - val_loss: 1.0353 - val_acc: 0.8015\n",
      "Epoch 258/700\n",
      "3689/3689 [==============================] - 2s 437us/step - loss: 0.1953 - acc: 0.9396 - val_loss: 1.0685 - val_acc: 0.8061\n",
      "Epoch 259/700\n",
      "3689/3689 [==============================] - 2s 433us/step - loss: 0.2098 - acc: 0.9398 - val_loss: 1.0383 - val_acc: 0.7996\n",
      "Epoch 260/700\n",
      "3689/3689 [==============================] - 2s 463us/step - loss: 0.2063 - acc: 0.9377 - val_loss: 1.0469 - val_acc: 0.8058\n",
      "Epoch 261/700\n",
      "3689/3689 [==============================] - 2s 432us/step - loss: 0.1997 - acc: 0.9371 - val_loss: 1.0359 - val_acc: 0.7993\n",
      "Epoch 262/700\n",
      "3689/3689 [==============================] - 2s 486us/step - loss: 0.1862 - acc: 0.9420 - val_loss: 1.0721 - val_acc: 0.7993\n",
      "Epoch 263/700\n",
      "3689/3689 [==============================] - 2s 621us/step - loss: 0.2011 - acc: 0.9423 - val_loss: 1.0149 - val_acc: 0.8052\n",
      "Epoch 264/700\n",
      "3689/3689 [==============================] - 2s 528us/step - loss: 0.1794 - acc: 0.9431 - val_loss: 1.0497 - val_acc: 0.8055\n",
      "Epoch 265/700\n",
      "3689/3689 [==============================] - 2s 580us/step - loss: 0.1613 - acc: 0.9485 - val_loss: 1.0436 - val_acc: 0.8091\n",
      "Epoch 266/700\n",
      "3689/3689 [==============================] - 2s 472us/step - loss: 0.1610 - acc: 0.9542 - val_loss: 1.0451 - val_acc: 0.8061\n",
      "Epoch 267/700\n",
      "3689/3689 [==============================] - 2s 465us/step - loss: 0.2120 - acc: 0.9401 - val_loss: 1.1267 - val_acc: 0.7892\n",
      "Epoch 268/700\n",
      "3689/3689 [==============================] - 2s 512us/step - loss: 0.2281 - acc: 0.9333 - val_loss: 1.0756 - val_acc: 0.7990\n",
      "Epoch 269/700\n",
      "3689/3689 [==============================] - 2s 636us/step - loss: 0.1862 - acc: 0.9444 - val_loss: 1.0538 - val_acc: 0.8079\n",
      "Epoch 270/700\n",
      "3689/3689 [==============================] - 3s 702us/step - loss: 0.1688 - acc: 0.9501 - val_loss: 1.0409 - val_acc: 0.8082\n",
      "Epoch 271/700\n",
      "3689/3689 [==============================] - 2s 492us/step - loss: 0.1702 - acc: 0.9444 - val_loss: 1.0678 - val_acc: 0.8058\n",
      "Epoch 272/700\n",
      "3689/3689 [==============================] - 2s 587us/step - loss: 0.1555 - acc: 0.9496 - val_loss: 1.0594 - val_acc: 0.8073\n",
      "Epoch 273/700\n",
      "3689/3689 [==============================] - 2s 625us/step - loss: 0.1451 - acc: 0.9553 - val_loss: 1.0520 - val_acc: 0.8082\n",
      "Epoch 274/700\n",
      "3689/3689 [==============================] - 2s 617us/step - loss: 0.1406 - acc: 0.9566 - val_loss: 1.0987 - val_acc: 0.8048\n",
      "Epoch 275/700\n",
      "3689/3689 [==============================] - 2s 545us/step - loss: 0.1416 - acc: 0.9577 - val_loss: 1.0806 - val_acc: 0.8070\n",
      "Epoch 276/700\n",
      "3689/3689 [==============================] - 2s 552us/step - loss: 0.1467 - acc: 0.9517 - val_loss: 1.1255 - val_acc: 0.8079\n",
      "Epoch 277/700\n",
      "3689/3689 [==============================] - 2s 568us/step - loss: 0.1499 - acc: 0.9499 - val_loss: 1.0963 - val_acc: 0.8067\n",
      "Epoch 278/700\n",
      "3689/3689 [==============================] - 2s 594us/step - loss: 0.1319 - acc: 0.9585 - val_loss: 1.1301 - val_acc: 0.8073\n",
      "Epoch 279/700\n",
      "3689/3689 [==============================] - 2s 575us/step - loss: 0.1388 - acc: 0.9577 - val_loss: 1.2662 - val_acc: 0.7883\n",
      "Epoch 280/700\n",
      "3689/3689 [==============================] - 2s 544us/step - loss: 0.3358 - acc: 0.9095 - val_loss: 1.0571 - val_acc: 0.7966\n",
      "Epoch 281/700\n",
      "3689/3689 [==============================] - 2s 562us/step - loss: 0.2745 - acc: 0.9222 - val_loss: 1.0018 - val_acc: 0.8033\n",
      "Epoch 282/700\n",
      "3689/3689 [==============================] - 2s 536us/step - loss: 0.2254 - acc: 0.9287 - val_loss: 1.0143 - val_acc: 0.7987\n",
      "Epoch 283/700\n",
      "3689/3689 [==============================] - 2s 661us/step - loss: 0.1795 - acc: 0.9425 - val_loss: 0.9930 - val_acc: 0.8052\n",
      "Epoch 284/700\n",
      "3689/3689 [==============================] - 2s 554us/step - loss: 0.1943 - acc: 0.9409 - val_loss: 1.0261 - val_acc: 0.8018\n",
      "Epoch 285/700\n",
      "3689/3689 [==============================] - 2s 478us/step - loss: 0.1823 - acc: 0.9442 - val_loss: 1.0226 - val_acc: 0.8088\n",
      "Epoch 286/700\n",
      "3689/3689 [==============================] - 2s 498us/step - loss: 0.1639 - acc: 0.9477 - val_loss: 0.9878 - val_acc: 0.8076\n",
      "Epoch 287/700\n",
      "3689/3689 [==============================] - 2s 469us/step - loss: 0.1655 - acc: 0.9471 - val_loss: 1.0056 - val_acc: 0.8085\n",
      "Epoch 288/700\n",
      "3689/3689 [==============================] - 2s 471us/step - loss: 0.1491 - acc: 0.9550 - val_loss: 1.0216 - val_acc: 0.8113\n",
      "Epoch 289/700\n",
      "3689/3689 [==============================] - 2s 485us/step - loss: 0.1410 - acc: 0.9539 - val_loss: 1.0587 - val_acc: 0.8116\n",
      "Epoch 290/700\n",
      "3689/3689 [==============================] - 2s 467us/step - loss: 0.1404 - acc: 0.9555 - val_loss: 1.0589 - val_acc: 0.8107\n",
      "Epoch 291/700\n",
      "3689/3689 [==============================] - 2s 464us/step - loss: 0.1584 - acc: 0.9496 - val_loss: 1.0535 - val_acc: 0.8091\n",
      "Epoch 292/700\n",
      "3689/3689 [==============================] - 2s 581us/step - loss: 0.1682 - acc: 0.9477 - val_loss: 1.1052 - val_acc: 0.8082\n",
      "Epoch 293/700\n",
      "3689/3689 [==============================] - 2s 469us/step - loss: 0.1615 - acc: 0.9490 - val_loss: 1.0704 - val_acc: 0.8104\n",
      "Epoch 294/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3689/3689 [==============================] - 2s 472us/step - loss: 0.1530 - acc: 0.9515 - val_loss: 1.1029 - val_acc: 0.8107\n",
      "Epoch 295/700\n",
      "3689/3689 [==============================] - 2s 458us/step - loss: 0.1466 - acc: 0.9515 - val_loss: 1.0928 - val_acc: 0.8122\n",
      "Epoch 296/700\n",
      "3689/3689 [==============================] - 2s 467us/step - loss: 0.1492 - acc: 0.9553 - val_loss: 1.0815 - val_acc: 0.8134\n",
      "Epoch 297/700\n",
      "3689/3689 [==============================] - 2s 475us/step - loss: 0.2112 - acc: 0.9406 - val_loss: 1.0778 - val_acc: 0.8045\n",
      "Epoch 298/700\n",
      "3689/3689 [==============================] - 2s 470us/step - loss: 0.1994 - acc: 0.9379 - val_loss: 1.0630 - val_acc: 0.8024\n",
      "Epoch 299/700\n",
      "3689/3689 [==============================] - 2s 475us/step - loss: 0.1658 - acc: 0.9471 - val_loss: 1.0629 - val_acc: 0.8082\n",
      "Epoch 300/700\n",
      "3689/3689 [==============================] - 2s 469us/step - loss: 0.1514 - acc: 0.9534 - val_loss: 1.1040 - val_acc: 0.8070\n",
      "Epoch 301/700\n",
      "3689/3689 [==============================] - 2s 518us/step - loss: 0.1483 - acc: 0.9542 - val_loss: 1.0585 - val_acc: 0.8113\n",
      "Epoch 302/700\n",
      "3689/3689 [==============================] - 2s 582us/step - loss: 0.1425 - acc: 0.9534 - val_loss: 1.1107 - val_acc: 0.8119\n",
      "Epoch 303/700\n",
      "3689/3689 [==============================] - 2s 610us/step - loss: 0.1374 - acc: 0.9591 - val_loss: 1.0901 - val_acc: 0.8147\n",
      "Epoch 304/700\n",
      "3689/3689 [==============================] - 2s 464us/step - loss: 0.1350 - acc: 0.9550 - val_loss: 1.1132 - val_acc: 0.8153\n",
      "Epoch 305/700\n",
      "3689/3689 [==============================] - 2s 467us/step - loss: 0.1456 - acc: 0.9542 - val_loss: 1.1703 - val_acc: 0.8064\n",
      "Epoch 306/700\n",
      "3689/3689 [==============================] - 2s 643us/step - loss: 0.1844 - acc: 0.9512 - val_loss: 1.1157 - val_acc: 0.8006\n",
      "Epoch 307/700\n",
      "3689/3689 [==============================] - 2s 471us/step - loss: 0.1627 - acc: 0.9499 - val_loss: 1.1069 - val_acc: 0.8052\n",
      "Epoch 308/700\n",
      "3689/3689 [==============================] - 2s 466us/step - loss: 0.1591 - acc: 0.9517 - val_loss: 1.1055 - val_acc: 0.8052\n",
      "Epoch 309/700\n",
      "3689/3689 [==============================] - 2s 467us/step - loss: 0.1437 - acc: 0.9534 - val_loss: 1.0644 - val_acc: 0.8064\n",
      "Epoch 310/700\n",
      "3689/3689 [==============================] - 2s 463us/step - loss: 0.1480 - acc: 0.9542 - val_loss: 1.1469 - val_acc: 0.8091\n",
      "Epoch 311/700\n",
      "3689/3689 [==============================] - 2s 473us/step - loss: 0.1478 - acc: 0.9553 - val_loss: 1.0739 - val_acc: 0.8150\n",
      "Epoch 312/700\n",
      "3689/3689 [==============================] - 2s 465us/step - loss: 0.1344 - acc: 0.9634 - val_loss: 1.0921 - val_acc: 0.8101\n",
      "Epoch 313/700\n",
      "3689/3689 [==============================] - 2s 467us/step - loss: 0.1348 - acc: 0.9574 - val_loss: 1.1385 - val_acc: 0.8125\n",
      "Epoch 314/700\n",
      "3689/3689 [==============================] - 2s 462us/step - loss: 0.1267 - acc: 0.9604 - val_loss: 1.1185 - val_acc: 0.8144\n",
      "Epoch 315/700\n",
      "3689/3689 [==============================] - 2s 488us/step - loss: 0.1245 - acc: 0.9620 - val_loss: 1.1477 - val_acc: 0.8156\n",
      "Epoch 316/700\n",
      "3689/3689 [==============================] - 2s 488us/step - loss: 0.1272 - acc: 0.9610 - val_loss: 1.1242 - val_acc: 0.8128\n",
      "Epoch 317/700\n",
      "3689/3689 [==============================] - 2s 471us/step - loss: 0.1230 - acc: 0.9596 - val_loss: 1.1653 - val_acc: 0.8156\n",
      "Epoch 318/700\n",
      "3689/3689 [==============================] - 2s 468us/step - loss: 0.1202 - acc: 0.9637 - val_loss: 1.1957 - val_acc: 0.8122\n",
      "Epoch 319/700\n",
      "3689/3689 [==============================] - 2s 470us/step - loss: 0.1205 - acc: 0.9612 - val_loss: 1.1746 - val_acc: 0.8095\n",
      "Epoch 320/700\n",
      "3689/3689 [==============================] - 2s 468us/step - loss: 0.1157 - acc: 0.9626 - val_loss: 1.1797 - val_acc: 0.8141\n",
      "Epoch 321/700\n",
      "3689/3689 [==============================] - 2s 466us/step - loss: 0.1054 - acc: 0.9675 - val_loss: 1.1965 - val_acc: 0.8122\n",
      "Epoch 322/700\n",
      "3689/3689 [==============================] - 2s 484us/step - loss: 0.1077 - acc: 0.9626 - val_loss: 1.2029 - val_acc: 0.8165\n",
      "Epoch 323/700\n",
      "3689/3689 [==============================] - 2s 503us/step - loss: 0.1212 - acc: 0.9626 - val_loss: 1.1766 - val_acc: 0.8168\n",
      "Epoch 324/700\n",
      "3689/3689 [==============================] - 2s 651us/step - loss: 0.1220 - acc: 0.9620 - val_loss: 1.1666 - val_acc: 0.8113\n",
      "Epoch 325/700\n",
      "3689/3689 [==============================] - 3s 795us/step - loss: 0.1457 - acc: 0.9558 - val_loss: 1.1808 - val_acc: 0.8116\n",
      "Epoch 326/700\n",
      "3689/3689 [==============================] - 2s 662us/step - loss: 0.1185 - acc: 0.9645 - val_loss: 1.1867 - val_acc: 0.8147\n",
      "Epoch 327/700\n",
      "3689/3689 [==============================] - 3s 712us/step - loss: 0.1171 - acc: 0.9639 - val_loss: 1.1819 - val_acc: 0.8153\n",
      "Epoch 328/700\n",
      "3689/3689 [==============================] - 3s 684us/step - loss: 0.1101 - acc: 0.9650 - val_loss: 1.2235 - val_acc: 0.8147\n",
      "Epoch 329/700\n",
      "3689/3689 [==============================] - 2s 654us/step - loss: 0.1168 - acc: 0.9650 - val_loss: 1.2261 - val_acc: 0.8098\n",
      "Epoch 330/700\n",
      "3689/3689 [==============================] - 3s 729us/step - loss: 0.1243 - acc: 0.9626 - val_loss: 1.2224 - val_acc: 0.8058\n",
      "Epoch 331/700\n",
      "3689/3689 [==============================] - 3s 822us/step - loss: 0.1174 - acc: 0.9620 - val_loss: 1.2779 - val_acc: 0.8104\n",
      "Epoch 332/700\n",
      "3689/3689 [==============================] - 2s 630us/step - loss: 0.1246 - acc: 0.9604 - val_loss: 1.2496 - val_acc: 0.8067\n",
      "Epoch 333/700\n",
      "3689/3689 [==============================] - 2s 637us/step - loss: 0.1606 - acc: 0.9528 - val_loss: 1.2244 - val_acc: 0.8070\n",
      "Epoch 334/700\n",
      "3689/3689 [==============================] - 2s 613us/step - loss: 0.1990 - acc: 0.9480 - val_loss: 1.2146 - val_acc: 0.8018\n",
      "Epoch 335/700\n",
      "3689/3689 [==============================] - 2s 629us/step - loss: 0.2143 - acc: 0.9423 - val_loss: 1.1252 - val_acc: 0.8076\n",
      "Epoch 336/700\n",
      "3689/3689 [==============================] - 2s 609us/step - loss: 0.1656 - acc: 0.9461 - val_loss: 1.1535 - val_acc: 0.8055\n",
      "Epoch 337/700\n",
      "3689/3689 [==============================] - 2s 657us/step - loss: 0.1550 - acc: 0.9572 - val_loss: 1.0992 - val_acc: 0.8150\n",
      "Epoch 338/700\n",
      "3689/3689 [==============================] - 2s 621us/step - loss: 0.1403 - acc: 0.9569 - val_loss: 1.0965 - val_acc: 0.8168\n",
      "Epoch 339/700\n",
      "3689/3689 [==============================] - 2s 627us/step - loss: 0.1247 - acc: 0.9618 - val_loss: 1.1359 - val_acc: 0.8119\n",
      "Epoch 340/700\n",
      "3689/3689 [==============================] - 2s 633us/step - loss: 0.1135 - acc: 0.9664 - val_loss: 1.1255 - val_acc: 0.8085\n",
      "Epoch 341/700\n",
      "3689/3689 [==============================] - 2s 635us/step - loss: 0.1104 - acc: 0.9656 - val_loss: 1.1589 - val_acc: 0.8134\n",
      "Epoch 342/700\n",
      "3689/3689 [==============================] - 3s 686us/step - loss: 0.0989 - acc: 0.9683 - val_loss: 1.1533 - val_acc: 0.8122\n",
      "Epoch 343/700\n",
      "3689/3689 [==============================] - 2s 644us/step - loss: 0.1116 - acc: 0.9645 - val_loss: 1.1774 - val_acc: 0.8168\n",
      "Epoch 344/700\n",
      "3689/3689 [==============================] - 2s 647us/step - loss: 0.0990 - acc: 0.9677 - val_loss: 1.1993 - val_acc: 0.8168\n",
      "Epoch 345/700\n",
      "3689/3689 [==============================] - 3s 705us/step - loss: 0.0926 - acc: 0.9707 - val_loss: 1.2289 - val_acc: 0.8137\n",
      "Epoch 346/700\n",
      "3689/3689 [==============================] - 2s 621us/step - loss: 0.0981 - acc: 0.9694 - val_loss: 1.2627 - val_acc: 0.8134\n",
      "Epoch 347/700\n",
      "3689/3689 [==============================] - 2s 608us/step - loss: 0.0968 - acc: 0.9724 - val_loss: 1.2443 - val_acc: 0.8156\n",
      "Epoch 348/700\n",
      "3689/3689 [==============================] - 3s 688us/step - loss: 0.0961 - acc: 0.9707 - val_loss: 1.2581 - val_acc: 0.8156\n",
      "Epoch 349/700\n",
      "3689/3689 [==============================] - 3s 724us/step - loss: 0.0910 - acc: 0.9718 - val_loss: 1.2745 - val_acc: 0.8131\n",
      "Epoch 350/700\n",
      "3689/3689 [==============================] - 2s 598us/step - loss: 0.1200 - acc: 0.9667 - val_loss: 1.3180 - val_acc: 0.8061\n",
      "Epoch 351/700\n",
      "3689/3689 [==============================] - 2s 606us/step - loss: 0.1802 - acc: 0.9499 - val_loss: 1.3364 - val_acc: 0.7981\n",
      "Epoch 352/700\n",
      "3689/3689 [==============================] - 2s 609us/step - loss: 0.2021 - acc: 0.9444 - val_loss: 1.1773 - val_acc: 0.8088\n",
      "Epoch 353/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3689/3689 [==============================] - 2s 556us/step - loss: 0.1633 - acc: 0.9553 - val_loss: 1.1327 - val_acc: 0.8137\n",
      "Epoch 354/700\n",
      "3689/3689 [==============================] - 2s 550us/step - loss: 0.1441 - acc: 0.9534 - val_loss: 1.1470 - val_acc: 0.8144\n",
      "Epoch 355/700\n",
      "3689/3689 [==============================] - 2s 577us/step - loss: 0.1467 - acc: 0.9591 - val_loss: 1.1473 - val_acc: 0.8131\n",
      "Epoch 356/700\n",
      "3689/3689 [==============================] - 2s 574us/step - loss: 0.1342 - acc: 0.9566 - val_loss: 1.1650 - val_acc: 0.8141\n",
      "Epoch 357/700\n",
      "3689/3689 [==============================] - 2s 576us/step - loss: 0.1264 - acc: 0.9623 - val_loss: 1.1603 - val_acc: 0.8134\n",
      "Epoch 358/700\n",
      "3689/3689 [==============================] - 2s 663us/step - loss: 0.1195 - acc: 0.9637 - val_loss: 1.1531 - val_acc: 0.8137\n",
      "Epoch 359/700\n",
      "3689/3689 [==============================] - 2s 636us/step - loss: 0.1008 - acc: 0.9702 - val_loss: 1.2003 - val_acc: 0.8125\n",
      "Epoch 360/700\n",
      "3689/3689 [==============================] - 2s 612us/step - loss: 0.1131 - acc: 0.9691 - val_loss: 1.1947 - val_acc: 0.8183\n",
      "Epoch 361/700\n",
      "3689/3689 [==============================] - 2s 576us/step - loss: 0.1619 - acc: 0.9574 - val_loss: 1.1868 - val_acc: 0.8193\n",
      "Epoch 362/700\n",
      "3689/3689 [==============================] - 2s 594us/step - loss: 0.1731 - acc: 0.9471 - val_loss: 1.2170 - val_acc: 0.8021\n",
      "Epoch 363/700\n",
      "3689/3689 [==============================] - 2s 596us/step - loss: 0.1294 - acc: 0.9623 - val_loss: 1.1507 - val_acc: 0.8116\n",
      "Epoch 364/700\n",
      "3689/3689 [==============================] - 2s 646us/step - loss: 0.1103 - acc: 0.9653 - val_loss: 1.2073 - val_acc: 0.8159\n",
      "Epoch 365/700\n",
      "3689/3689 [==============================] - 2s 596us/step - loss: 0.1296 - acc: 0.9612 - val_loss: 1.1605 - val_acc: 0.8122\n",
      "Epoch 366/700\n",
      "3689/3689 [==============================] - 2s 622us/step - loss: 0.1106 - acc: 0.9667 - val_loss: 1.1850 - val_acc: 0.8141\n",
      "Epoch 367/700\n",
      "3689/3689 [==============================] - 2s 655us/step - loss: 0.1086 - acc: 0.9658 - val_loss: 1.1821 - val_acc: 0.8122\n",
      "Epoch 368/700\n",
      "3689/3689 [==============================] - 2s 627us/step - loss: 0.1178 - acc: 0.9639 - val_loss: 1.3013 - val_acc: 0.7910\n",
      "Epoch 369/700\n",
      "3689/3689 [==============================] - 2s 626us/step - loss: 0.2096 - acc: 0.9444 - val_loss: 1.1657 - val_acc: 0.8048\n",
      "Epoch 370/700\n",
      "3689/3689 [==============================] - 2s 608us/step - loss: 0.1805 - acc: 0.9493 - val_loss: 1.1707 - val_acc: 0.8064\n",
      "Epoch 371/700\n",
      "3689/3689 [==============================] - 2s 613us/step - loss: 0.1586 - acc: 0.9539 - val_loss: 1.1235 - val_acc: 0.8141\n",
      "Epoch 372/700\n",
      "3689/3689 [==============================] - 2s 624us/step - loss: 0.1378 - acc: 0.9599 - val_loss: 1.1312 - val_acc: 0.8119\n",
      "Epoch 373/700\n",
      "3689/3689 [==============================] - 2s 594us/step - loss: 0.1312 - acc: 0.9620 - val_loss: 1.1200 - val_acc: 0.8165\n",
      "Epoch 374/700\n",
      "3689/3689 [==============================] - 2s 619us/step - loss: 0.1119 - acc: 0.9661 - val_loss: 1.1323 - val_acc: 0.8156\n",
      "Epoch 375/700\n",
      "3689/3689 [==============================] - 2s 600us/step - loss: 0.1133 - acc: 0.9667 - val_loss: 1.1773 - val_acc: 0.8122\n",
      "Epoch 376/700\n",
      "3689/3689 [==============================] - 3s 693us/step - loss: 0.1874 - acc: 0.9461 - val_loss: 1.2110 - val_acc: 0.7920\n",
      "Epoch 377/700\n",
      "3689/3689 [==============================] - 2s 567us/step - loss: 0.2035 - acc: 0.9406 - val_loss: 1.1692 - val_acc: 0.7984\n",
      "Epoch 378/700\n",
      "3689/3689 [==============================] - 2s 553us/step - loss: 0.2285 - acc: 0.9385 - val_loss: 1.0941 - val_acc: 0.8119\n",
      "Epoch 379/700\n",
      "3689/3689 [==============================] - 2s 537us/step - loss: 0.2182 - acc: 0.9414 - val_loss: 1.1269 - val_acc: 0.8045\n",
      "Epoch 380/700\n",
      "3689/3689 [==============================] - 2s 547us/step - loss: 0.2026 - acc: 0.9452 - val_loss: 1.0270 - val_acc: 0.8156\n",
      "Epoch 381/700\n",
      "3689/3689 [==============================] - 2s 558us/step - loss: 0.1716 - acc: 0.9485 - val_loss: 1.0637 - val_acc: 0.8165\n",
      "Epoch 382/700\n",
      "3689/3689 [==============================] - 2s 543us/step - loss: 0.1486 - acc: 0.9553 - val_loss: 1.0473 - val_acc: 0.8196\n",
      "Epoch 383/700\n",
      "3689/3689 [==============================] - 2s 540us/step - loss: 0.1445 - acc: 0.9602 - val_loss: 1.0906 - val_acc: 0.8180\n",
      "Epoch 384/700\n",
      "3689/3689 [==============================] - 2s 544us/step - loss: 0.1277 - acc: 0.9637 - val_loss: 1.0936 - val_acc: 0.8202\n",
      "Epoch 385/700\n",
      "3689/3689 [==============================] - 2s 539us/step - loss: 0.1261 - acc: 0.9596 - val_loss: 1.1005 - val_acc: 0.8168\n",
      "Epoch 386/700\n",
      "3689/3689 [==============================] - 2s 526us/step - loss: 0.1137 - acc: 0.9669 - val_loss: 1.1213 - val_acc: 0.8180\n",
      "Epoch 387/700\n",
      "3689/3689 [==============================] - 2s 563us/step - loss: 0.1086 - acc: 0.9699 - val_loss: 1.1305 - val_acc: 0.8190\n",
      "Epoch 388/700\n",
      "3689/3689 [==============================] - 2s 541us/step - loss: 0.1033 - acc: 0.9699 - val_loss: 1.1488 - val_acc: 0.8220\n",
      "Epoch 389/700\n",
      "3689/3689 [==============================] - 2s 550us/step - loss: 0.1010 - acc: 0.9688 - val_loss: 1.1744 - val_acc: 0.8220\n",
      "Epoch 390/700\n",
      "3689/3689 [==============================] - 2s 612us/step - loss: 0.0999 - acc: 0.9710 - val_loss: 1.1799 - val_acc: 0.8199\n",
      "Epoch 391/700\n",
      "3689/3689 [==============================] - 2s 634us/step - loss: 0.0932 - acc: 0.9715 - val_loss: 1.1485 - val_acc: 0.8208\n",
      "Epoch 392/700\n",
      "3689/3689 [==============================] - 2s 555us/step - loss: 0.1071 - acc: 0.9683 - val_loss: 1.1610 - val_acc: 0.8217\n",
      "Epoch 393/700\n",
      "3689/3689 [==============================] - 2s 533us/step - loss: 0.1064 - acc: 0.9699 - val_loss: 1.2156 - val_acc: 0.8165\n",
      "Epoch 394/700\n",
      "3689/3689 [==============================] - 2s 551us/step - loss: 0.1090 - acc: 0.9675 - val_loss: 1.1967 - val_acc: 0.8208\n",
      "Epoch 395/700\n",
      "3689/3689 [==============================] - 2s 556us/step - loss: 0.0869 - acc: 0.9772 - val_loss: 1.2073 - val_acc: 0.8226\n",
      "Epoch 396/700\n",
      "3689/3689 [==============================] - 2s 552us/step - loss: 0.0995 - acc: 0.9713 - val_loss: 1.2154 - val_acc: 0.8254\n",
      "Epoch 397/700\n",
      "3689/3689 [==============================] - 2s 549us/step - loss: 0.1081 - acc: 0.9686 - val_loss: 1.1847 - val_acc: 0.8193\n",
      "Epoch 398/700\n",
      "3689/3689 [==============================] - 2s 568us/step - loss: 0.1002 - acc: 0.9688 - val_loss: 1.1802 - val_acc: 0.8245\n",
      "Epoch 399/700\n",
      "3689/3689 [==============================] - 2s 566us/step - loss: 0.1124 - acc: 0.9675 - val_loss: 1.1972 - val_acc: 0.8257\n",
      "Epoch 400/700\n",
      "3689/3689 [==============================] - 2s 546us/step - loss: 0.1434 - acc: 0.9634 - val_loss: 1.1540 - val_acc: 0.8233\n",
      "Epoch 401/700\n",
      "3689/3689 [==============================] - 2s 555us/step - loss: 0.1504 - acc: 0.9583 - val_loss: 1.2857 - val_acc: 0.7935\n",
      "Epoch 402/700\n",
      "3689/3689 [==============================] - 3s 710us/step - loss: 0.3006 - acc: 0.9322 - val_loss: 1.1839 - val_acc: 0.8082\n",
      "Epoch 403/700\n",
      "3689/3689 [==============================] - 2s 546us/step - loss: 0.2279 - acc: 0.9382 - val_loss: 1.0978 - val_acc: 0.8107\n",
      "Epoch 404/700\n",
      "3689/3689 [==============================] - 2s 551us/step - loss: 0.2065 - acc: 0.9390 - val_loss: 1.0608 - val_acc: 0.8193\n",
      "Epoch 405/700\n",
      "3689/3689 [==============================] - 2s 556us/step - loss: 0.2203 - acc: 0.9428 - val_loss: 1.1078 - val_acc: 0.8122\n",
      "Epoch 406/700\n",
      "3689/3689 [==============================] - 2s 541us/step - loss: 0.2329 - acc: 0.9374 - val_loss: 1.0053 - val_acc: 0.8251\n",
      "Epoch 407/700\n",
      "3689/3689 [==============================] - 2s 552us/step - loss: 0.1701 - acc: 0.9493 - val_loss: 1.0161 - val_acc: 0.8208\n",
      "Epoch 408/700\n",
      "3689/3689 [==============================] - 2s 552us/step - loss: 0.1579 - acc: 0.9542 - val_loss: 0.9975 - val_acc: 0.8214\n",
      "Epoch 409/700\n",
      "3689/3689 [==============================] - 2s 556us/step - loss: 0.1385 - acc: 0.9610 - val_loss: 1.0351 - val_acc: 0.8196\n",
      "Epoch 410/700\n",
      "3689/3689 [==============================] - 2s 556us/step - loss: 0.1366 - acc: 0.9604 - val_loss: 1.0879 - val_acc: 0.8190\n",
      "Epoch 411/700\n",
      "3689/3689 [==============================] - 2s 544us/step - loss: 0.1273 - acc: 0.9612 - val_loss: 1.0873 - val_acc: 0.8183\n",
      "Epoch 412/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3689/3689 [==============================] - 2s 544us/step - loss: 0.1191 - acc: 0.9675 - val_loss: 1.1066 - val_acc: 0.8208\n",
      "Epoch 413/700\n",
      "3689/3689 [==============================] - 2s 595us/step - loss: 0.1096 - acc: 0.9686 - val_loss: 1.1338 - val_acc: 0.8187\n",
      "Epoch 414/700\n",
      "3689/3689 [==============================] - 2s 477us/step - loss: 0.1127 - acc: 0.9629 - val_loss: 1.1326 - val_acc: 0.8202\n",
      "Epoch 415/700\n",
      "3689/3689 [==============================] - 2s 513us/step - loss: 0.1079 - acc: 0.9691 - val_loss: 1.1509 - val_acc: 0.8226\n",
      "Epoch 416/700\n",
      "3689/3689 [==============================] - 2s 538us/step - loss: 0.0980 - acc: 0.9715 - val_loss: 1.1649 - val_acc: 0.8217\n",
      "Epoch 417/700\n",
      "3689/3689 [==============================] - 2s 550us/step - loss: 0.0977 - acc: 0.9748 - val_loss: 1.1642 - val_acc: 0.8211\n",
      "Epoch 418/700\n",
      "3689/3689 [==============================] - 2s 563us/step - loss: 0.0905 - acc: 0.9751 - val_loss: 1.1969 - val_acc: 0.8233\n",
      "Epoch 419/700\n",
      "3689/3689 [==============================] - 2s 616us/step - loss: 0.0998 - acc: 0.9702 - val_loss: 1.1999 - val_acc: 0.8220\n",
      "Epoch 420/700\n",
      "3689/3689 [==============================] - 2s 587us/step - loss: 0.0948 - acc: 0.9734 - val_loss: 1.2049 - val_acc: 0.8242\n",
      "Epoch 421/700\n",
      "3689/3689 [==============================] - 2s 507us/step - loss: 0.0894 - acc: 0.9756 - val_loss: 1.2242 - val_acc: 0.8202\n",
      "Epoch 422/700\n",
      "3689/3689 [==============================] - 2s 514us/step - loss: 0.0894 - acc: 0.9721 - val_loss: 1.2175 - val_acc: 0.8211\n",
      "Epoch 423/700\n",
      "3689/3689 [==============================] - 2s 514us/step - loss: 0.0869 - acc: 0.9756 - val_loss: 1.2465 - val_acc: 0.8220\n",
      "Epoch 424/700\n",
      "3689/3689 [==============================] - 2s 527us/step - loss: 0.0905 - acc: 0.9759 - val_loss: 1.2467 - val_acc: 0.8180\n",
      "Epoch 425/700\n",
      "3689/3689 [==============================] - 2s 516us/step - loss: 0.1001 - acc: 0.9705 - val_loss: 1.2040 - val_acc: 0.8187\n",
      "Epoch 426/700\n",
      "3689/3689 [==============================] - 3s 714us/step - loss: 0.0923 - acc: 0.9732 - val_loss: 1.2193 - val_acc: 0.8226\n",
      "Epoch 427/700\n",
      "3689/3689 [==============================] - 3s 716us/step - loss: 0.0840 - acc: 0.9732 - val_loss: 1.2415 - val_acc: 0.8230\n",
      "Epoch 428/700\n",
      "3689/3689 [==============================] - 2s 535us/step - loss: 0.0918 - acc: 0.9751 - val_loss: 1.2597 - val_acc: 0.8223\n",
      "Epoch 429/700\n",
      "3689/3689 [==============================] - 2s 553us/step - loss: 0.0984 - acc: 0.9734 - val_loss: 1.2422 - val_acc: 0.8202\n",
      "Epoch 430/700\n",
      "3689/3689 [==============================] - 2s 598us/step - loss: 0.1199 - acc: 0.9656 - val_loss: 1.2231 - val_acc: 0.8217\n",
      "Epoch 431/700\n",
      "3689/3689 [==============================] - 2s 617us/step - loss: 0.1197 - acc: 0.9667 - val_loss: 1.1815 - val_acc: 0.8239\n",
      "Epoch 432/700\n",
      "3689/3689 [==============================] - 2s 566us/step - loss: 0.1249 - acc: 0.9661 - val_loss: 1.2161 - val_acc: 0.8153\n",
      "Epoch 433/700\n",
      "3689/3689 [==============================] - 2s 527us/step - loss: 0.2971 - acc: 0.9352 - val_loss: 1.5311 - val_acc: 0.7536\n",
      "Epoch 434/700\n",
      "3689/3689 [==============================] - 2s 533us/step - loss: 0.5215 - acc: 0.8718 - val_loss: 1.0629 - val_acc: 0.7972\n",
      "Epoch 435/700\n",
      "3689/3689 [==============================] - 2s 605us/step - loss: 0.3487 - acc: 0.9081 - val_loss: 0.9851 - val_acc: 0.8012\n",
      "Epoch 436/700\n",
      "3689/3689 [==============================] - 2s 597us/step - loss: 0.2900 - acc: 0.9133 - val_loss: 0.9704 - val_acc: 0.8033\n",
      "Epoch 437/700\n",
      "3689/3689 [==============================] - 2s 585us/step - loss: 0.2567 - acc: 0.9303 - val_loss: 0.9430 - val_acc: 0.8101\n",
      "Epoch 438/700\n",
      "3689/3689 [==============================] - 2s 525us/step - loss: 0.2312 - acc: 0.9355 - val_loss: 0.9323 - val_acc: 0.8125\n",
      "Epoch 439/700\n",
      "3689/3689 [==============================] - 2s 554us/step - loss: 0.1931 - acc: 0.9452 - val_loss: 0.9203 - val_acc: 0.8168\n",
      "Epoch 440/700\n",
      "3689/3689 [==============================] - 2s 564us/step - loss: 0.1691 - acc: 0.9496 - val_loss: 0.9232 - val_acc: 0.8223\n",
      "Epoch 441/700\n",
      "3689/3689 [==============================] - 2s 548us/step - loss: 0.1636 - acc: 0.9515 - val_loss: 0.9528 - val_acc: 0.8211\n",
      "Epoch 442/700\n",
      "3689/3689 [==============================] - 2s 567us/step - loss: 0.1535 - acc: 0.9569 - val_loss: 0.9908 - val_acc: 0.8202\n",
      "Epoch 443/700\n",
      "3689/3689 [==============================] - 2s 563us/step - loss: 0.1476 - acc: 0.9591 - val_loss: 1.0145 - val_acc: 0.8202\n",
      "Epoch 444/700\n",
      "3689/3689 [==============================] - 2s 576us/step - loss: 0.1363 - acc: 0.9610 - val_loss: 1.0087 - val_acc: 0.8239\n",
      "Epoch 445/700\n",
      "3689/3689 [==============================] - 3s 698us/step - loss: 0.1313 - acc: 0.9620 - val_loss: 1.0171 - val_acc: 0.8226\n",
      "Epoch 446/700\n",
      "3689/3689 [==============================] - 2s 629us/step - loss: 0.1275 - acc: 0.9667 - val_loss: 1.0309 - val_acc: 0.8223\n",
      "Epoch 447/700\n",
      "3689/3689 [==============================] - 2s 597us/step - loss: 0.1257 - acc: 0.9645 - val_loss: 1.0371 - val_acc: 0.8239\n",
      "Epoch 448/700\n",
      "3689/3689 [==============================] - 2s 579us/step - loss: 0.1391 - acc: 0.9572 - val_loss: 1.0293 - val_acc: 0.8214\n",
      "Epoch 449/700\n",
      "3689/3689 [==============================] - 2s 534us/step - loss: 0.1307 - acc: 0.9631 - val_loss: 1.0332 - val_acc: 0.8251\n",
      "Epoch 450/700\n",
      "3689/3689 [==============================] - 2s 550us/step - loss: 0.1152 - acc: 0.9658 - val_loss: 1.0596 - val_acc: 0.8242\n",
      "Epoch 451/700\n",
      "3689/3689 [==============================] - 2s 541us/step - loss: 0.1133 - acc: 0.9664 - val_loss: 1.0592 - val_acc: 0.8205\n",
      "Epoch 452/700\n",
      "3689/3689 [==============================] - 2s 544us/step - loss: 0.1250 - acc: 0.9612 - val_loss: 1.0834 - val_acc: 0.8202\n",
      "Epoch 453/700\n",
      "3689/3689 [==============================] - 2s 542us/step - loss: 0.1120 - acc: 0.9661 - val_loss: 1.1107 - val_acc: 0.8230\n",
      "Epoch 454/700\n",
      "3689/3689 [==============================] - 2s 534us/step - loss: 0.1065 - acc: 0.9672 - val_loss: 1.1068 - val_acc: 0.8269\n",
      "Epoch 455/700\n",
      "3689/3689 [==============================] - 2s 538us/step - loss: 0.0946 - acc: 0.9707 - val_loss: 1.1114 - val_acc: 0.8254\n",
      "Epoch 456/700\n",
      "3689/3689 [==============================] - 2s 559us/step - loss: 0.0949 - acc: 0.9713 - val_loss: 1.1108 - val_acc: 0.8263\n",
      "Epoch 457/700\n",
      "3689/3689 [==============================] - 2s 548us/step - loss: 0.0861 - acc: 0.9745 - val_loss: 1.1127 - val_acc: 0.8276\n",
      "Epoch 458/700\n",
      "3689/3689 [==============================] - 2s 567us/step - loss: 0.0865 - acc: 0.9737 - val_loss: 1.1249 - val_acc: 0.8269\n",
      "Epoch 459/700\n",
      "3689/3689 [==============================] - 2s 555us/step - loss: 0.0825 - acc: 0.9745 - val_loss: 1.1446 - val_acc: 0.8272\n",
      "Epoch 460/700\n",
      "3689/3689 [==============================] - 2s 551us/step - loss: 0.0856 - acc: 0.9742 - val_loss: 1.1563 - val_acc: 0.8257\n",
      "Epoch 461/700\n",
      "3689/3689 [==============================] - 2s 621us/step - loss: 0.0866 - acc: 0.9742 - val_loss: 1.1476 - val_acc: 0.8279\n",
      "Epoch 462/700\n",
      "3689/3689 [==============================] - 2s 635us/step - loss: 0.0830 - acc: 0.9751 - val_loss: 1.1716 - val_acc: 0.8251\n",
      "Epoch 463/700\n",
      "3689/3689 [==============================] - 2s 660us/step - loss: 0.0788 - acc: 0.9783 - val_loss: 1.1794 - val_acc: 0.8266\n",
      "Epoch 464/700\n",
      "3689/3689 [==============================] - 2s 644us/step - loss: 0.0807 - acc: 0.9764 - val_loss: 1.1915 - val_acc: 0.8294\n",
      "Epoch 465/700\n",
      "3689/3689 [==============================] - 2s 625us/step - loss: 0.0781 - acc: 0.9786 - val_loss: 1.2161 - val_acc: 0.8263\n",
      "Epoch 466/700\n",
      "3689/3689 [==============================] - 2s 644us/step - loss: 0.0818 - acc: 0.9778 - val_loss: 1.2143 - val_acc: 0.8297\n",
      "Epoch 467/700\n",
      "3689/3689 [==============================] - 2s 631us/step - loss: 0.0855 - acc: 0.9734 - val_loss: 1.2378 - val_acc: 0.8269\n",
      "Epoch 468/700\n",
      "3689/3689 [==============================] - 2s 633us/step - loss: 0.0812 - acc: 0.9748 - val_loss: 1.2188 - val_acc: 0.8291\n",
      "Epoch 469/700\n",
      "3689/3689 [==============================] - 2s 634us/step - loss: 0.0792 - acc: 0.9745 - val_loss: 1.2259 - val_acc: 0.8282\n",
      "Epoch 470/700\n",
      "3689/3689 [==============================] - 2s 649us/step - loss: 0.0880 - acc: 0.9756 - val_loss: 1.2133 - val_acc: 0.8260\n",
      "Epoch 471/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3689/3689 [==============================] - 2s 581us/step - loss: 0.0788 - acc: 0.9786 - val_loss: 1.2468 - val_acc: 0.8269\n",
      "Epoch 472/700\n",
      "3689/3689 [==============================] - 2s 584us/step - loss: 0.0793 - acc: 0.9740 - val_loss: 1.2078 - val_acc: 0.8291\n",
      "Epoch 473/700\n",
      "3689/3689 [==============================] - 2s 594us/step - loss: 0.0786 - acc: 0.9764 - val_loss: 1.2309 - val_acc: 0.8291\n",
      "Epoch 474/700\n",
      "3689/3689 [==============================] - 2s 605us/step - loss: 0.0801 - acc: 0.9780 - val_loss: 1.2478 - val_acc: 0.8279\n",
      "Epoch 475/700\n",
      "3689/3689 [==============================] - 2s 661us/step - loss: 0.0845 - acc: 0.9772 - val_loss: 1.2520 - val_acc: 0.8300\n",
      "Epoch 476/700\n",
      "3689/3689 [==============================] - 2s 520us/step - loss: 0.0838 - acc: 0.9737 - val_loss: 1.2799 - val_acc: 0.8285\n",
      "Epoch 477/700\n",
      "3689/3689 [==============================] - 2s 531us/step - loss: 0.0816 - acc: 0.9751 - val_loss: 1.2552 - val_acc: 0.8254\n",
      "Epoch 478/700\n",
      "3689/3689 [==============================] - 2s 515us/step - loss: 0.1149 - acc: 0.9710 - val_loss: 1.2534 - val_acc: 0.8269\n",
      "Epoch 479/700\n",
      "3689/3689 [==============================] - 2s 493us/step - loss: 0.1397 - acc: 0.9626 - val_loss: 1.2114 - val_acc: 0.8236\n",
      "Epoch 480/700\n",
      "3689/3689 [==============================] - 3s 720us/step - loss: 0.1936 - acc: 0.9493 - val_loss: 1.1978 - val_acc: 0.8141\n",
      "Epoch 481/700\n",
      "3689/3689 [==============================] - 4s 1ms/step - loss: 0.1596 - acc: 0.9580 - val_loss: 1.1816 - val_acc: 0.8190\n",
      "Epoch 482/700\n",
      "3689/3689 [==============================] - 4s 1ms/step - loss: 0.1476 - acc: 0.9591 - val_loss: 1.1327 - val_acc: 0.8233\n",
      "Epoch 483/700\n",
      "3689/3689 [==============================] - 3s 887us/step - loss: 0.1324 - acc: 0.9648 - val_loss: 1.1348 - val_acc: 0.8254\n",
      "Epoch 484/700\n",
      "3689/3689 [==============================] - 3s 825us/step - loss: 0.1239 - acc: 0.9623 - val_loss: 1.1859 - val_acc: 0.8150\n",
      "Epoch 485/700\n",
      "3689/3689 [==============================] - 3s 830us/step - loss: 0.1863 - acc: 0.9564 - val_loss: 1.1583 - val_acc: 0.8223\n",
      "Epoch 486/700\n",
      "3689/3689 [==============================] - 3s 839us/step - loss: 0.1548 - acc: 0.9596 - val_loss: 1.1206 - val_acc: 0.8211\n",
      "Epoch 487/700\n",
      "3689/3689 [==============================] - 3s 823us/step - loss: 0.1267 - acc: 0.9664 - val_loss: 1.1083 - val_acc: 0.8279\n",
      "Epoch 488/700\n",
      "3689/3689 [==============================] - 3s 787us/step - loss: 0.1117 - acc: 0.9658 - val_loss: 1.1120 - val_acc: 0.8282\n",
      "Epoch 489/700\n",
      "3689/3689 [==============================] - 3s 769us/step - loss: 0.1101 - acc: 0.9702 - val_loss: 1.1125 - val_acc: 0.8276\n",
      "Epoch 490/700\n",
      "3689/3689 [==============================] - 3s 780us/step - loss: 0.0979 - acc: 0.9732 - val_loss: 1.1179 - val_acc: 0.8328\n",
      "Epoch 491/700\n",
      "3689/3689 [==============================] - 3s 787us/step - loss: 0.1118 - acc: 0.9699 - val_loss: 1.0569 - val_acc: 0.8309\n",
      "Epoch 492/700\n",
      "3689/3689 [==============================] - 3s 786us/step - loss: 0.1433 - acc: 0.9618 - val_loss: 1.0804 - val_acc: 0.8291\n",
      "Epoch 493/700\n",
      "3689/3689 [==============================] - 3s 773us/step - loss: 0.1332 - acc: 0.9658 - val_loss: 1.0798 - val_acc: 0.8322\n",
      "Epoch 494/700\n",
      "3689/3689 [==============================] - 3s 913us/step - loss: 0.1136 - acc: 0.9696 - val_loss: 1.0711 - val_acc: 0.8346\n",
      "Epoch 495/700\n",
      "3689/3689 [==============================] - 3s 796us/step - loss: 0.0905 - acc: 0.9732 - val_loss: 1.1029 - val_acc: 0.8340\n",
      "Epoch 496/700\n",
      "3689/3689 [==============================] - 3s 806us/step - loss: 0.0853 - acc: 0.9740 - val_loss: 1.1018 - val_acc: 0.8349\n",
      "Epoch 497/700\n",
      "3689/3689 [==============================] - 3s 790us/step - loss: 0.1594 - acc: 0.9569 - val_loss: 1.1530 - val_acc: 0.8319\n",
      "Epoch 498/700\n",
      "3689/3689 [==============================] - 3s 821us/step - loss: 0.1915 - acc: 0.9463 - val_loss: 1.1186 - val_acc: 0.8251\n",
      "Epoch 499/700\n",
      "3689/3689 [==============================] - 3s 824us/step - loss: 0.2328 - acc: 0.9428 - val_loss: 1.0346 - val_acc: 0.8233\n",
      "Epoch 500/700\n",
      "3689/3689 [==============================] - 3s 775us/step - loss: 0.1787 - acc: 0.9463 - val_loss: 1.0352 - val_acc: 0.8291\n",
      "Epoch 501/700\n",
      "3689/3689 [==============================] - 3s 775us/step - loss: 0.1646 - acc: 0.9526 - val_loss: 1.0461 - val_acc: 0.8196\n",
      "Epoch 502/700\n",
      "3689/3689 [==============================] - 3s 816us/step - loss: 0.1435 - acc: 0.9604 - val_loss: 1.0192 - val_acc: 0.8315\n",
      "Epoch 503/700\n",
      "3689/3689 [==============================] - 3s 828us/step - loss: 0.1126 - acc: 0.9675 - val_loss: 1.0107 - val_acc: 0.8365\n",
      "Epoch 504/700\n",
      "3689/3689 [==============================] - 3s 931us/step - loss: 0.0985 - acc: 0.9718 - val_loss: 1.0331 - val_acc: 0.8377\n",
      "Epoch 505/700\n",
      "3689/3689 [==============================] - 3s 840us/step - loss: 0.1027 - acc: 0.9718 - val_loss: 1.0401 - val_acc: 0.8361\n",
      "Epoch 506/700\n",
      "3689/3689 [==============================] - 3s 783us/step - loss: 0.0992 - acc: 0.9718 - val_loss: 1.0838 - val_acc: 0.8306\n",
      "Epoch 507/700\n",
      "3689/3689 [==============================] - 3s 871us/step - loss: 0.1184 - acc: 0.9683 - val_loss: 1.0598 - val_acc: 0.8380\n",
      "Epoch 508/700\n",
      "3689/3689 [==============================] - 3s 918us/step - loss: 0.1071 - acc: 0.9680 - val_loss: 1.0660 - val_acc: 0.8294\n",
      "Epoch 509/700\n",
      "3689/3689 [==============================] - 2s 555us/step - loss: 0.1129 - acc: 0.9683 - val_loss: 1.0804 - val_acc: 0.8319\n",
      "Epoch 510/700\n",
      "3689/3689 [==============================] - 2s 647us/step - loss: 0.1102 - acc: 0.9677 - val_loss: 1.0800 - val_acc: 0.8386\n",
      "Epoch 511/700\n",
      "3689/3689 [==============================] - 2s 593us/step - loss: 0.0979 - acc: 0.9707 - val_loss: 1.0560 - val_acc: 0.8386\n",
      "Epoch 512/700\n",
      "3689/3689 [==============================] - 3s 719us/step - loss: 0.0835 - acc: 0.9737 - val_loss: 1.0655 - val_acc: 0.8389\n",
      "Epoch 513/700\n",
      "3689/3689 [==============================] - 2s 656us/step - loss: 0.0845 - acc: 0.9759 - val_loss: 1.0853 - val_acc: 0.8407\n",
      "Epoch 514/700\n",
      "3689/3689 [==============================] - 2s 671us/step - loss: 0.1156 - acc: 0.9688 - val_loss: 1.0885 - val_acc: 0.8352\n",
      "Epoch 515/700\n",
      "3689/3689 [==============================] - 3s 737us/step - loss: 0.0926 - acc: 0.9729 - val_loss: 1.0671 - val_acc: 0.8371\n",
      "Epoch 516/700\n",
      "3689/3689 [==============================] - 2s 650us/step - loss: 0.0964 - acc: 0.9699 - val_loss: 1.0953 - val_acc: 0.8374\n",
      "Epoch 517/700\n",
      "3689/3689 [==============================] - 2s 642us/step - loss: 0.1512 - acc: 0.9588 - val_loss: 1.1224 - val_acc: 0.8266\n",
      "Epoch 518/700\n",
      "3689/3689 [==============================] - 2s 625us/step - loss: 0.1436 - acc: 0.9580 - val_loss: 1.0334 - val_acc: 0.8263\n",
      "Epoch 519/700\n",
      "3689/3689 [==============================] - 2s 587us/step - loss: 0.1233 - acc: 0.9653 - val_loss: 1.0491 - val_acc: 0.8288\n",
      "Epoch 520/700\n",
      "3689/3689 [==============================] - 3s 712us/step - loss: 0.1062 - acc: 0.9669 - val_loss: 1.0487 - val_acc: 0.8325\n",
      "Epoch 521/700\n",
      "3689/3689 [==============================] - 2s 627us/step - loss: 0.0915 - acc: 0.9726 - val_loss: 1.0586 - val_acc: 0.8337\n",
      "Epoch 522/700\n",
      "3689/3689 [==============================] - 2s 608us/step - loss: 0.0939 - acc: 0.9729 - val_loss: 1.0712 - val_acc: 0.8328\n",
      "Epoch 523/700\n",
      "3689/3689 [==============================] - 2s 628us/step - loss: 0.0788 - acc: 0.9748 - val_loss: 1.0845 - val_acc: 0.8328\n",
      "Epoch 524/700\n",
      "3689/3689 [==============================] - 2s 641us/step - loss: 0.0905 - acc: 0.9745 - val_loss: 1.1445 - val_acc: 0.8337\n",
      "Epoch 525/700\n",
      "3689/3689 [==============================] - 2s 655us/step - loss: 0.1275 - acc: 0.9686 - val_loss: 1.0749 - val_acc: 0.8383\n",
      "Epoch 526/700\n",
      "3689/3689 [==============================] - 2s 677us/step - loss: 0.1077 - acc: 0.9680 - val_loss: 1.0770 - val_acc: 0.8260\n",
      "Epoch 527/700\n",
      "3689/3689 [==============================] - 2s 555us/step - loss: 0.2869 - acc: 0.9276 - val_loss: 1.0846 - val_acc: 0.8208\n",
      "Epoch 528/700\n",
      "3689/3689 [==============================] - 2s 604us/step - loss: 0.3048 - acc: 0.9295 - val_loss: 1.2376 - val_acc: 0.7910\n",
      "Epoch 529/700\n",
      "3689/3689 [==============================] - 2s 513us/step - loss: 0.3791 - acc: 0.9024 - val_loss: 1.0652 - val_acc: 0.8055\n",
      "Epoch 530/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3689/3689 [==============================] - 2s 550us/step - loss: 0.2850 - acc: 0.9230 - val_loss: 0.9685 - val_acc: 0.8159\n",
      "Epoch 531/700\n",
      "3689/3689 [==============================] - 2s 542us/step - loss: 0.2657 - acc: 0.9292 - val_loss: 0.9965 - val_acc: 0.8220\n",
      "Epoch 532/700\n",
      "3689/3689 [==============================] - 2s 474us/step - loss: 0.2307 - acc: 0.9398 - val_loss: 0.9549 - val_acc: 0.8263\n",
      "Epoch 533/700\n",
      "3689/3689 [==============================] - 2s 488us/step - loss: 0.1756 - acc: 0.9480 - val_loss: 0.9468 - val_acc: 0.8269\n",
      "Epoch 534/700\n",
      "3689/3689 [==============================] - 2s 479us/step - loss: 0.1549 - acc: 0.9531 - val_loss: 0.9810 - val_acc: 0.8337\n",
      "Epoch 535/700\n",
      "3689/3689 [==============================] - 2s 470us/step - loss: 0.1637 - acc: 0.9523 - val_loss: 0.9815 - val_acc: 0.8309\n",
      "Epoch 536/700\n",
      "3689/3689 [==============================] - 2s 472us/step - loss: 0.1398 - acc: 0.9577 - val_loss: 0.9734 - val_acc: 0.8300\n",
      "Epoch 537/700\n",
      "3689/3689 [==============================] - 2s 475us/step - loss: 0.1266 - acc: 0.9588 - val_loss: 1.0045 - val_acc: 0.8325\n",
      "Epoch 538/700\n",
      "3689/3689 [==============================] - 2s 471us/step - loss: 0.1148 - acc: 0.9648 - val_loss: 1.0083 - val_acc: 0.8368\n",
      "Epoch 539/700\n",
      "3689/3689 [==============================] - 2s 480us/step - loss: 0.1158 - acc: 0.9648 - val_loss: 1.0168 - val_acc: 0.8352\n",
      "Epoch 540/700\n",
      "3689/3689 [==============================] - 2s 476us/step - loss: 0.1089 - acc: 0.9680 - val_loss: 1.0200 - val_acc: 0.8383\n",
      "Epoch 541/700\n",
      "3689/3689 [==============================] - 2s 474us/step - loss: 0.1121 - acc: 0.9677 - val_loss: 1.0416 - val_acc: 0.8368\n",
      "Epoch 542/700\n",
      "3689/3689 [==============================] - 2s 483us/step - loss: 0.1105 - acc: 0.9669 - val_loss: 1.0497 - val_acc: 0.8343\n",
      "Epoch 543/700\n",
      "3689/3689 [==============================] - 2s 508us/step - loss: 0.0977 - acc: 0.9702 - val_loss: 1.0368 - val_acc: 0.8377\n",
      "Epoch 544/700\n",
      "3689/3689 [==============================] - 2s 545us/step - loss: 0.1053 - acc: 0.9650 - val_loss: 1.0659 - val_acc: 0.8380\n",
      "Epoch 545/700\n",
      "3689/3689 [==============================] - 2s 552us/step - loss: 0.0945 - acc: 0.9737 - val_loss: 1.0572 - val_acc: 0.8380\n",
      "Epoch 546/700\n",
      "3689/3689 [==============================] - 2s 513us/step - loss: 0.0944 - acc: 0.9683 - val_loss: 1.0670 - val_acc: 0.8395\n",
      "Epoch 547/700\n",
      "3689/3689 [==============================] - 2s 522us/step - loss: 0.1065 - acc: 0.9699 - val_loss: 1.1098 - val_acc: 0.8242\n",
      "Epoch 548/700\n",
      "3689/3689 [==============================] - 2s 484us/step - loss: 0.1709 - acc: 0.9574 - val_loss: 1.1113 - val_acc: 0.8325\n",
      "Epoch 549/700\n",
      "3689/3689 [==============================] - 2s 476us/step - loss: 0.1426 - acc: 0.9604 - val_loss: 1.0576 - val_acc: 0.8322\n",
      "Epoch 550/700\n",
      "3689/3689 [==============================] - 2s 503us/step - loss: 0.1186 - acc: 0.9626 - val_loss: 1.0567 - val_acc: 0.8361\n",
      "Epoch 551/700\n",
      "3689/3689 [==============================] - 2s 490us/step - loss: 0.1211 - acc: 0.9667 - val_loss: 1.0587 - val_acc: 0.8395\n",
      "Epoch 552/700\n",
      "3689/3689 [==============================] - 2s 480us/step - loss: 0.1032 - acc: 0.9696 - val_loss: 1.0311 - val_acc: 0.8398\n",
      "Epoch 553/700\n",
      "3689/3689 [==============================] - 2s 599us/step - loss: 0.0927 - acc: 0.9707 - val_loss: 1.0399 - val_acc: 0.8414\n",
      "Epoch 554/700\n",
      "3689/3689 [==============================] - 2s 608us/step - loss: 0.0945 - acc: 0.9710 - val_loss: 1.0332 - val_acc: 0.8398\n",
      "Epoch 555/700\n",
      "3689/3689 [==============================] - 2s 636us/step - loss: 0.0929 - acc: 0.9694 - val_loss: 1.0348 - val_acc: 0.8420\n",
      "Epoch 556/700\n",
      "3689/3689 [==============================] - 3s 703us/step - loss: 0.0912 - acc: 0.9729 - val_loss: 1.0614 - val_acc: 0.8450\n",
      "Epoch 557/700\n",
      "3689/3689 [==============================] - 2s 674us/step - loss: 0.0870 - acc: 0.9756 - val_loss: 1.0313 - val_acc: 0.8447\n",
      "Epoch 558/700\n",
      "3689/3689 [==============================] - 2s 638us/step - loss: 0.0976 - acc: 0.9707 - val_loss: 1.0552 - val_acc: 0.8426\n",
      "Epoch 559/700\n",
      "3689/3689 [==============================] - 2s 622us/step - loss: 0.0852 - acc: 0.9745 - val_loss: 1.0567 - val_acc: 0.8423\n",
      "Epoch 560/700\n",
      "3689/3689 [==============================] - 2s 623us/step - loss: 0.0832 - acc: 0.9740 - val_loss: 1.0707 - val_acc: 0.8423\n",
      "Epoch 561/700\n",
      "3689/3689 [==============================] - 2s 594us/step - loss: 0.0759 - acc: 0.9764 - val_loss: 1.0961 - val_acc: 0.8423\n",
      "Epoch 562/700\n",
      "3689/3689 [==============================] - 2s 594us/step - loss: 0.0784 - acc: 0.9751 - val_loss: 1.1044 - val_acc: 0.8429\n",
      "Epoch 563/700\n",
      "3689/3689 [==============================] - 2s 594us/step - loss: 0.0842 - acc: 0.9745 - val_loss: 1.0924 - val_acc: 0.8457\n",
      "Epoch 564/700\n",
      "3689/3689 [==============================] - 2s 627us/step - loss: 0.0783 - acc: 0.9753 - val_loss: 1.0757 - val_acc: 0.8429\n",
      "Epoch 565/700\n",
      "3689/3689 [==============================] - 2s 648us/step - loss: 0.1019 - acc: 0.9721 - val_loss: 1.3169 - val_acc: 0.8331\n",
      "Epoch 566/700\n",
      "3689/3689 [==============================] - 2s 677us/step - loss: 0.1745 - acc: 0.9555 - val_loss: 1.1578 - val_acc: 0.8300\n",
      "Epoch 567/700\n",
      "3689/3689 [==============================] - 2s 648us/step - loss: 0.1202 - acc: 0.9680 - val_loss: 1.1719 - val_acc: 0.8322\n",
      "Epoch 568/700\n",
      "3689/3689 [==============================] - 2s 662us/step - loss: 0.1462 - acc: 0.9588 - val_loss: 1.0440 - val_acc: 0.8300\n",
      "Epoch 569/700\n",
      "3689/3689 [==============================] - 2s 542us/step - loss: 0.1235 - acc: 0.9656 - val_loss: 1.0985 - val_acc: 0.8371\n",
      "Epoch 570/700\n",
      "3689/3689 [==============================] - 3s 856us/step - loss: 0.0840 - acc: 0.9732 - val_loss: 1.0850 - val_acc: 0.8346\n",
      "Epoch 571/700\n",
      "3689/3689 [==============================] - 4s 954us/step - loss: 0.1741 - acc: 0.9580 - val_loss: 1.0737 - val_acc: 0.8260\n",
      "Epoch 572/700\n",
      "3689/3689 [==============================] - 2s 615us/step - loss: 0.1421 - acc: 0.9591 - val_loss: 1.0750 - val_acc: 0.8328\n",
      "Epoch 573/700\n",
      "3689/3689 [==============================] - 2s 594us/step - loss: 0.1101 - acc: 0.9680 - val_loss: 1.0582 - val_acc: 0.8352\n",
      "Epoch 574/700\n",
      "3689/3689 [==============================] - 2s 676us/step - loss: 0.0935 - acc: 0.9715 - val_loss: 1.0719 - val_acc: 0.8309\n",
      "Epoch 575/700\n",
      "3689/3689 [==============================] - 2s 612us/step - loss: 0.1202 - acc: 0.9639 - val_loss: 1.0901 - val_acc: 0.8334\n",
      "Epoch 576/700\n",
      "3689/3689 [==============================] - 2s 630us/step - loss: 0.1013 - acc: 0.9699 - val_loss: 1.0949 - val_acc: 0.8331\n",
      "Epoch 577/700\n",
      "3689/3689 [==============================] - 2s 588us/step - loss: 0.0942 - acc: 0.9707 - val_loss: 1.0990 - val_acc: 0.8386\n",
      "Epoch 578/700\n",
      "3689/3689 [==============================] - 2s 572us/step - loss: 0.0876 - acc: 0.9740 - val_loss: 1.1109 - val_acc: 0.8371\n",
      "Epoch 579/700\n",
      "3689/3689 [==============================] - 2s 543us/step - loss: 0.0941 - acc: 0.9713 - val_loss: 1.1105 - val_acc: 0.8371\n",
      "Epoch 580/700\n",
      "3689/3689 [==============================] - 2s 574us/step - loss: 0.0744 - acc: 0.9799 - val_loss: 1.1244 - val_acc: 0.8389\n",
      "Epoch 581/700\n",
      "3689/3689 [==============================] - 2s 629us/step - loss: 0.0824 - acc: 0.9770 - val_loss: 1.1249 - val_acc: 0.8349\n",
      "Epoch 582/700\n",
      "3689/3689 [==============================] - 2s 586us/step - loss: 0.0822 - acc: 0.9734 - val_loss: 1.1376 - val_acc: 0.8395\n",
      "Epoch 583/700\n",
      "3689/3689 [==============================] - 2s 604us/step - loss: 0.0765 - acc: 0.9783 - val_loss: 1.1520 - val_acc: 0.8374\n",
      "Epoch 584/700\n",
      "3689/3689 [==============================] - 2s 559us/step - loss: 0.0761 - acc: 0.9786 - val_loss: 1.1469 - val_acc: 0.8383\n",
      "Epoch 585/700\n",
      "3689/3689 [==============================] - 2s 591us/step - loss: 0.0767 - acc: 0.9761 - val_loss: 1.1524 - val_acc: 0.8383\n",
      "Epoch 586/700\n",
      "3689/3689 [==============================] - 3s 778us/step - loss: 0.0683 - acc: 0.9829 - val_loss: 1.1645 - val_acc: 0.8377\n",
      "Epoch 587/700\n",
      "3689/3689 [==============================] - 2s 584us/step - loss: 0.0754 - acc: 0.9772 - val_loss: 1.1522 - val_acc: 0.8389\n",
      "Epoch 588/700\n",
      "3689/3689 [==============================] - 4s 1ms/step - loss: 0.0675 - acc: 0.9805 - val_loss: 1.1599 - val_acc: 0.8411\n",
      "Epoch 589/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3689/3689 [==============================] - 2s 641us/step - loss: 0.0795 - acc: 0.9734 - val_loss: 1.2236 - val_acc: 0.8361\n",
      "Epoch 590/700\n",
      "3689/3689 [==============================] - 2s 524us/step - loss: 0.0992 - acc: 0.9745 - val_loss: 1.1851 - val_acc: 0.8398\n",
      "Epoch 591/700\n",
      "3689/3689 [==============================] - 2s 598us/step - loss: 0.0811 - acc: 0.9791 - val_loss: 1.1955 - val_acc: 0.8389\n",
      "Epoch 592/700\n",
      "3689/3689 [==============================] - 2s 541us/step - loss: 0.0877 - acc: 0.9761 - val_loss: 1.1828 - val_acc: 0.8414\n",
      "Epoch 593/700\n",
      "3689/3689 [==============================] - 2s 479us/step - loss: 0.0766 - acc: 0.9778 - val_loss: 1.1975 - val_acc: 0.8414\n",
      "Epoch 594/700\n",
      "3689/3689 [==============================] - 2s 623us/step - loss: 0.0690 - acc: 0.9808 - val_loss: 1.1985 - val_acc: 0.8420\n",
      "Epoch 595/700\n",
      "3689/3689 [==============================] - 3s 740us/step - loss: 0.0711 - acc: 0.9829 - val_loss: 1.1877 - val_acc: 0.8355\n",
      "Epoch 596/700\n",
      "3689/3689 [==============================] - 2s 583us/step - loss: 0.0736 - acc: 0.9789 - val_loss: 1.1946 - val_acc: 0.8392\n",
      "Epoch 597/700\n",
      "3689/3689 [==============================] - 2s 576us/step - loss: 0.0625 - acc: 0.9829 - val_loss: 1.2045 - val_acc: 0.8414\n",
      "Epoch 598/700\n",
      "3689/3689 [==============================] - 2s 528us/step - loss: 0.0701 - acc: 0.9799 - val_loss: 1.2132 - val_acc: 0.8426\n",
      "Epoch 599/700\n",
      "3689/3689 [==============================] - 2s 552us/step - loss: 0.0611 - acc: 0.9818 - val_loss: 1.2377 - val_acc: 0.8411\n",
      "Epoch 600/700\n",
      "3689/3689 [==============================] - 2s 558us/step - loss: 0.0630 - acc: 0.9816 - val_loss: 1.2396 - val_acc: 0.8404\n",
      "Epoch 601/700\n",
      "3689/3689 [==============================] - 3s 690us/step - loss: 0.0624 - acc: 0.9840 - val_loss: 1.2466 - val_acc: 0.8411\n",
      "Epoch 602/700\n",
      "3689/3689 [==============================] - 2s 473us/step - loss: 0.0689 - acc: 0.9789 - val_loss: 1.2392 - val_acc: 0.8398\n",
      "Epoch 603/700\n",
      "3689/3689 [==============================] - 2s 497us/step - loss: 0.0968 - acc: 0.9713 - val_loss: 1.1892 - val_acc: 0.8312\n",
      "Epoch 604/700\n",
      "3689/3689 [==============================] - 2s 564us/step - loss: 0.2490 - acc: 0.9463 - val_loss: 1.1884 - val_acc: 0.8319\n",
      "Epoch 605/700\n",
      "3689/3689 [==============================] - 2s 568us/step - loss: 0.1478 - acc: 0.9572 - val_loss: 1.1289 - val_acc: 0.8374\n",
      "Epoch 606/700\n",
      "3689/3689 [==============================] - 2s 561us/step - loss: 0.1230 - acc: 0.9648 - val_loss: 1.0818 - val_acc: 0.8447\n",
      "Epoch 607/700\n",
      "3689/3689 [==============================] - 3s 771us/step - loss: 0.1057 - acc: 0.9699 - val_loss: 1.1131 - val_acc: 0.8454\n",
      "Epoch 608/700\n",
      "3689/3689 [==============================] - 2s 609us/step - loss: 0.0864 - acc: 0.9751 - val_loss: 1.1169 - val_acc: 0.8457\n",
      "Epoch 609/700\n",
      "3689/3689 [==============================] - 2s 577us/step - loss: 0.1135 - acc: 0.9710 - val_loss: 1.1346 - val_acc: 0.8478\n",
      "Epoch 610/700\n",
      "3689/3689 [==============================] - 2s 584us/step - loss: 0.1116 - acc: 0.9707 - val_loss: 1.1079 - val_acc: 0.8404\n",
      "Epoch 611/700\n",
      "3689/3689 [==============================] - 2s 635us/step - loss: 0.1011 - acc: 0.9713 - val_loss: 1.1606 - val_acc: 0.8420\n",
      "Epoch 612/700\n",
      "3689/3689 [==============================] - 3s 792us/step - loss: 0.0887 - acc: 0.9732 - val_loss: 1.1236 - val_acc: 0.8432\n",
      "Epoch 613/700\n",
      "3689/3689 [==============================] - 2s 651us/step - loss: 0.1124 - acc: 0.9691 - val_loss: 1.1922 - val_acc: 0.8365\n",
      "Epoch 614/700\n",
      "3689/3689 [==============================] - 2s 638us/step - loss: 0.1370 - acc: 0.9634 - val_loss: 1.1614 - val_acc: 0.8398\n",
      "Epoch 615/700\n",
      "3689/3689 [==============================] - 2s 607us/step - loss: 0.0907 - acc: 0.9751 - val_loss: 1.1385 - val_acc: 0.8389\n",
      "Epoch 616/700\n",
      "3689/3689 [==============================] - 3s 755us/step - loss: 0.0849 - acc: 0.9732 - val_loss: 1.1342 - val_acc: 0.8411\n",
      "Epoch 617/700\n",
      "3689/3689 [==============================] - 3s 695us/step - loss: 0.0859 - acc: 0.9729 - val_loss: 1.1206 - val_acc: 0.8441\n",
      "Epoch 618/700\n",
      "3689/3689 [==============================] - 3s 679us/step - loss: 0.0745 - acc: 0.9764 - val_loss: 1.1536 - val_acc: 0.8454\n",
      "Epoch 619/700\n",
      "3689/3689 [==============================] - 3s 701us/step - loss: 0.0768 - acc: 0.9791 - val_loss: 1.1524 - val_acc: 0.8466\n",
      "Epoch 620/700\n",
      "3689/3689 [==============================] - 2s 636us/step - loss: 0.0616 - acc: 0.9799 - val_loss: 1.1674 - val_acc: 0.8469\n",
      "Epoch 621/700\n",
      "3689/3689 [==============================] - 2s 629us/step - loss: 0.0640 - acc: 0.9816 - val_loss: 1.1746 - val_acc: 0.8475\n",
      "Epoch 622/700\n",
      "3689/3689 [==============================] - 2s 625us/step - loss: 0.0591 - acc: 0.9818 - val_loss: 1.1809 - val_acc: 0.8475\n",
      "Epoch 623/700\n",
      "3689/3689 [==============================] - 3s 694us/step - loss: 0.0580 - acc: 0.9816 - val_loss: 1.2042 - val_acc: 0.8463\n",
      "Epoch 624/700\n",
      "3689/3689 [==============================] - 3s 697us/step - loss: 0.0507 - acc: 0.9835 - val_loss: 1.2083 - val_acc: 0.8466\n",
      "Epoch 625/700\n",
      "3689/3689 [==============================] - 2s 631us/step - loss: 0.0532 - acc: 0.9821 - val_loss: 1.2222 - val_acc: 0.8460\n",
      "Epoch 626/700\n",
      "3689/3689 [==============================] - 3s 696us/step - loss: 0.0604 - acc: 0.9808 - val_loss: 1.2452 - val_acc: 0.8463\n",
      "Epoch 627/700\n",
      "3689/3689 [==============================] - 2s 591us/step - loss: 0.0627 - acc: 0.9821 - val_loss: 1.2049 - val_acc: 0.8457\n",
      "Epoch 628/700\n",
      "3689/3689 [==============================] - 2s 596us/step - loss: 0.0627 - acc: 0.9802 - val_loss: 1.2280 - val_acc: 0.8447\n",
      "Epoch 629/700\n",
      "3689/3689 [==============================] - 2s 625us/step - loss: 0.0610 - acc: 0.9808 - val_loss: 1.2207 - val_acc: 0.8472\n",
      "Epoch 630/700\n",
      "3689/3689 [==============================] - 2s 643us/step - loss: 0.0483 - acc: 0.9837 - val_loss: 1.2472 - val_acc: 0.8466\n",
      "Epoch 631/700\n",
      "3689/3689 [==============================] - 3s 701us/step - loss: 0.0532 - acc: 0.9843 - val_loss: 1.2184 - val_acc: 0.8457\n",
      "Epoch 632/700\n",
      "3689/3689 [==============================] - 2s 653us/step - loss: 0.0473 - acc: 0.9832 - val_loss: 1.2268 - val_acc: 0.8444\n",
      "Epoch 633/700\n",
      "3689/3689 [==============================] - 2s 605us/step - loss: 0.0501 - acc: 0.9843 - val_loss: 1.2340 - val_acc: 0.8475\n",
      "Epoch 634/700\n",
      "3689/3689 [==============================] - 2s 597us/step - loss: 0.0522 - acc: 0.9837 - val_loss: 1.2706 - val_acc: 0.8481\n",
      "Epoch 635/700\n",
      "3689/3689 [==============================] - 2s 629us/step - loss: 0.0554 - acc: 0.9824 - val_loss: 1.2736 - val_acc: 0.8490\n",
      "Epoch 636/700\n",
      "3689/3689 [==============================] - 2s 597us/step - loss: 0.0466 - acc: 0.9840 - val_loss: 1.2550 - val_acc: 0.8457\n",
      "Epoch 637/700\n",
      "3689/3689 [==============================] - 2s 608us/step - loss: 0.0515 - acc: 0.9821 - val_loss: 1.2569 - val_acc: 0.8469\n",
      "Epoch 638/700\n",
      "3689/3689 [==============================] - 2s 605us/step - loss: 0.0483 - acc: 0.9835 - val_loss: 1.2534 - val_acc: 0.8481\n",
      "Epoch 639/700\n",
      "3689/3689 [==============================] - 2s 599us/step - loss: 0.0458 - acc: 0.9867 - val_loss: 1.2732 - val_acc: 0.8472\n",
      "Epoch 640/700\n",
      "3689/3689 [==============================] - 2s 591us/step - loss: 0.0453 - acc: 0.9848 - val_loss: 1.2693 - val_acc: 0.8457\n",
      "Epoch 641/700\n",
      "3689/3689 [==============================] - 2s 598us/step - loss: 0.0499 - acc: 0.9829 - val_loss: 1.2758 - val_acc: 0.8472\n",
      "Epoch 642/700\n",
      "3689/3689 [==============================] - 2s 647us/step - loss: 0.0474 - acc: 0.9837 - val_loss: 1.2981 - val_acc: 0.8469\n",
      "Epoch 643/700\n",
      "3689/3689 [==============================] - 3s 688us/step - loss: 0.0401 - acc: 0.9892 - val_loss: 1.3121 - val_acc: 0.8500\n",
      "Epoch 644/700\n",
      "3689/3689 [==============================] - 2s 612us/step - loss: 0.0438 - acc: 0.9862 - val_loss: 1.3092 - val_acc: 0.8481\n",
      "Epoch 645/700\n",
      "3689/3689 [==============================] - 2s 606us/step - loss: 0.0523 - acc: 0.9821 - val_loss: 1.3416 - val_acc: 0.8404\n",
      "Epoch 646/700\n",
      "3689/3689 [==============================] - 2s 608us/step - loss: 0.1647 - acc: 0.9577 - val_loss: 1.4826 - val_acc: 0.8226\n",
      "Epoch 647/700\n",
      "3689/3689 [==============================] - 2s 641us/step - loss: 0.2382 - acc: 0.9531 - val_loss: 1.2924 - val_acc: 0.8395\n",
      "Epoch 648/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3689/3689 [==============================] - 2s 552us/step - loss: 0.1301 - acc: 0.9677 - val_loss: 1.2518 - val_acc: 0.8380\n",
      "Epoch 649/700\n",
      "3689/3689 [==============================] - 2s 565us/step - loss: 0.1084 - acc: 0.9702 - val_loss: 1.2108 - val_acc: 0.8426\n",
      "Epoch 650/700\n",
      "3689/3689 [==============================] - 2s 551us/step - loss: 0.0857 - acc: 0.9756 - val_loss: 1.2114 - val_acc: 0.8404\n",
      "Epoch 651/700\n",
      "3689/3689 [==============================] - 2s 565us/step - loss: 0.1051 - acc: 0.9718 - val_loss: 1.1770 - val_acc: 0.8457\n",
      "Epoch 652/700\n",
      "3689/3689 [==============================] - 2s 670us/step - loss: 0.0846 - acc: 0.9745 - val_loss: 1.2080 - val_acc: 0.8441\n",
      "Epoch 653/700\n",
      "3689/3689 [==============================] - 2s 597us/step - loss: 0.0789 - acc: 0.9789 - val_loss: 1.1764 - val_acc: 0.8490\n",
      "Epoch 654/700\n",
      "3689/3689 [==============================] - 2s 575us/step - loss: 0.0598 - acc: 0.9799 - val_loss: 1.1825 - val_acc: 0.8490\n",
      "Epoch 655/700\n",
      "3689/3689 [==============================] - 2s 618us/step - loss: 0.0721 - acc: 0.9759 - val_loss: 1.2107 - val_acc: 0.8444\n",
      "Epoch 656/700\n",
      "3689/3689 [==============================] - 2s 656us/step - loss: 0.1187 - acc: 0.9707 - val_loss: 1.2436 - val_acc: 0.8358\n",
      "Epoch 657/700\n",
      "3689/3689 [==============================] - 2s 586us/step - loss: 0.1045 - acc: 0.9699 - val_loss: 1.2340 - val_acc: 0.8374\n",
      "Epoch 658/700\n",
      "3689/3689 [==============================] - 2s 587us/step - loss: 0.0907 - acc: 0.9745 - val_loss: 1.1555 - val_acc: 0.8411\n",
      "Epoch 659/700\n",
      "3689/3689 [==============================] - 2s 573us/step - loss: 0.0898 - acc: 0.9761 - val_loss: 1.2144 - val_acc: 0.8404\n",
      "Epoch 660/700\n",
      "3689/3689 [==============================] - 2s 580us/step - loss: 0.2062 - acc: 0.9523 - val_loss: 1.2953 - val_acc: 0.8214\n",
      "Epoch 661/700\n",
      "3689/3689 [==============================] - 2s 613us/step - loss: 0.2211 - acc: 0.9461 - val_loss: 1.1543 - val_acc: 0.8288\n",
      "Epoch 662/700\n",
      "3689/3689 [==============================] - 2s 617us/step - loss: 0.1578 - acc: 0.9580 - val_loss: 1.1134 - val_acc: 0.8334\n",
      "Epoch 663/700\n",
      "3689/3689 [==============================] - 2s 588us/step - loss: 0.1323 - acc: 0.9629 - val_loss: 1.1374 - val_acc: 0.8374\n",
      "Epoch 664/700\n",
      "3689/3689 [==============================] - 2s 572us/step - loss: 0.1168 - acc: 0.9661 - val_loss: 1.0516 - val_acc: 0.8432\n",
      "Epoch 665/700\n",
      "3689/3689 [==============================] - 2s 586us/step - loss: 0.1091 - acc: 0.9694 - val_loss: 1.0689 - val_acc: 0.8398\n",
      "Epoch 666/700\n",
      "3689/3689 [==============================] - 2s 576us/step - loss: 0.1181 - acc: 0.9707 - val_loss: 1.1440 - val_acc: 0.8395\n",
      "Epoch 667/700\n",
      "3689/3689 [==============================] - 2s 638us/step - loss: 0.1752 - acc: 0.9588 - val_loss: 1.2232 - val_acc: 0.7935\n",
      "Epoch 668/700\n",
      "3689/3689 [==============================] - 3s 678us/step - loss: 0.2859 - acc: 0.9127 - val_loss: 1.0676 - val_acc: 0.8180\n",
      "Epoch 669/700\n",
      "3689/3689 [==============================] - 2s 590us/step - loss: 0.3199 - acc: 0.9097 - val_loss: 1.1660 - val_acc: 0.7913\n",
      "Epoch 670/700\n",
      "3689/3689 [==============================] - 2s 596us/step - loss: 0.3437 - acc: 0.9086 - val_loss: 0.9269 - val_acc: 0.8202\n",
      "Epoch 671/700\n",
      "3689/3689 [==============================] - 2s 600us/step - loss: 0.2067 - acc: 0.9442 - val_loss: 0.9056 - val_acc: 0.8294\n",
      "Epoch 672/700\n",
      "3689/3689 [==============================] - 2s 618us/step - loss: 0.1810 - acc: 0.9501 - val_loss: 0.9352 - val_acc: 0.8355\n",
      "Epoch 673/700\n",
      "3689/3689 [==============================] - 2s 609us/step - loss: 0.1489 - acc: 0.9561 - val_loss: 0.9222 - val_acc: 0.8401\n",
      "Epoch 674/700\n",
      "3689/3689 [==============================] - 2s 612us/step - loss: 0.1357 - acc: 0.9629 - val_loss: 0.9350 - val_acc: 0.8438\n",
      "Epoch 675/700\n",
      "3689/3689 [==============================] - 2s 620us/step - loss: 0.1130 - acc: 0.9650 - val_loss: 0.9421 - val_acc: 0.8441\n",
      "Epoch 676/700\n",
      "3689/3689 [==============================] - 2s 605us/step - loss: 0.0950 - acc: 0.9753 - val_loss: 0.9667 - val_acc: 0.8457\n",
      "Epoch 677/700\n",
      "3689/3689 [==============================] - 2s 596us/step - loss: 0.0892 - acc: 0.9753 - val_loss: 0.9744 - val_acc: 0.8454\n",
      "Epoch 678/700\n",
      "3689/3689 [==============================] - 2s 600us/step - loss: 0.0902 - acc: 0.9732 - val_loss: 0.9662 - val_acc: 0.8500\n",
      "Epoch 679/700\n",
      "3689/3689 [==============================] - 2s 660us/step - loss: 0.0796 - acc: 0.9764 - val_loss: 0.9795 - val_acc: 0.8469\n",
      "Epoch 680/700\n",
      "3689/3689 [==============================] - 2s 655us/step - loss: 0.0815 - acc: 0.9756 - val_loss: 0.9909 - val_acc: 0.8481\n",
      "Epoch 681/700\n",
      "3689/3689 [==============================] - 3s 702us/step - loss: 0.0847 - acc: 0.9732 - val_loss: 1.0011 - val_acc: 0.8500\n",
      "Epoch 682/700\n",
      "3689/3689 [==============================] - 2s 658us/step - loss: 0.0773 - acc: 0.9791 - val_loss: 1.0024 - val_acc: 0.8490\n",
      "Epoch 683/700\n",
      "3689/3689 [==============================] - 2s 593us/step - loss: 0.0737 - acc: 0.9759 - val_loss: 1.0314 - val_acc: 0.8472\n",
      "Epoch 684/700\n",
      "3689/3689 [==============================] - 2s 616us/step - loss: 0.0740 - acc: 0.9778 - val_loss: 1.0259 - val_acc: 0.8503\n",
      "Epoch 685/700\n",
      "3689/3689 [==============================] - 2s 610us/step - loss: 0.0754 - acc: 0.9767 - val_loss: 1.0256 - val_acc: 0.8518\n",
      "Epoch 686/700\n",
      "3689/3689 [==============================] - 2s 596us/step - loss: 0.0773 - acc: 0.9767 - val_loss: 1.0293 - val_acc: 0.8546\n",
      "Epoch 687/700\n",
      "3689/3689 [==============================] - 2s 593us/step - loss: 0.0654 - acc: 0.9797 - val_loss: 1.0348 - val_acc: 0.8546\n",
      "Epoch 688/700\n",
      "3689/3689 [==============================] - 3s 680us/step - loss: 0.0622 - acc: 0.9808 - val_loss: 1.0562 - val_acc: 0.8536\n",
      "Epoch 689/700\n",
      "3689/3689 [==============================] - 2s 593us/step - loss: 0.0677 - acc: 0.9778 - val_loss: 1.0558 - val_acc: 0.8530\n",
      "Epoch 690/700\n",
      "3689/3689 [==============================] - 2s 598us/step - loss: 0.0614 - acc: 0.9829 - val_loss: 1.0665 - val_acc: 0.8509\n",
      "Epoch 691/700\n",
      "3689/3689 [==============================] - 2s 619us/step - loss: 0.0643 - acc: 0.9794 - val_loss: 1.0832 - val_acc: 0.8496\n",
      "Epoch 692/700\n",
      "3689/3689 [==============================] - 2s 613us/step - loss: 0.0640 - acc: 0.9810 - val_loss: 1.1047 - val_acc: 0.8466\n",
      "Epoch 693/700\n",
      "3689/3689 [==============================] - 2s 599us/step - loss: 0.0572 - acc: 0.9813 - val_loss: 1.0911 - val_acc: 0.8500\n",
      "Epoch 694/700\n",
      "3689/3689 [==============================] - 2s 614us/step - loss: 0.0606 - acc: 0.9794 - val_loss: 1.0894 - val_acc: 0.8515\n",
      "Epoch 695/700\n",
      "3689/3689 [==============================] - 3s 684us/step - loss: 0.0583 - acc: 0.9827 - val_loss: 1.1108 - val_acc: 0.8475\n",
      "Epoch 696/700\n",
      "3689/3689 [==============================] - 2s 669us/step - loss: 0.0588 - acc: 0.9832 - val_loss: 1.0946 - val_acc: 0.8512\n",
      "Epoch 697/700\n",
      "3689/3689 [==============================] - 2s 529us/step - loss: 0.0535 - acc: 0.9843 - val_loss: 1.1014 - val_acc: 0.8521\n",
      "Epoch 698/700\n",
      "3689/3689 [==============================] - 2s 538us/step - loss: 0.0534 - acc: 0.9837 - val_loss: 1.1107 - val_acc: 0.8524\n",
      "Epoch 699/700\n",
      "3689/3689 [==============================] - 2s 518us/step - loss: 0.0499 - acc: 0.9840 - val_loss: 1.1207 - val_acc: 0.8512\n",
      "Epoch 700/700\n",
      "3689/3689 [==============================] - 2s 534us/step - loss: 0.0489 - acc: 0.9832 - val_loss: 1.1327 - val_acc: 0.8506\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,batch_size=128 ,epochs=700,verbose=1,validation_data=(x_test,Y_test))\n",
    "model.save(\"asr.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8XFX9//HXmZns+942SZuW7qUL3UuhSAVkE5BFiqCCIqL4E8WvWOX7VRQUBFEQkUUWAVmlCMhWaCmUFrqkpXubNt2StGn2fU/m/P64dyaTZNJMkklm+zwfjzw6c+dm5pM2fc+Zc8+itNYIIYQILhZfFyCEEML7JNyFECIISbgLIUQQknAXQoggJOEuhBBBSMJdCCGCkIS7EEIEIQl3IYQIQhLuQggRhGy+euHU1FSdk5Pjq5cXQoiAtGXLlnKtdVpf5/ks3HNycsjNzfXVywshREBSSh315DzplhFCiCAk4S6EEEFIwl0IIYKQhLsQQgQhCXchhAhCEu5CCBGEJNyFECIIBVy4552o4/6V+6hubPV1KUII4bcCLtwPlzfwyJqDFFU1+boUIYTwWwEX7mlx4QCU17f4uBIhhPBfARfuqbERAJTXS7eMEEL0JoDDXVruQgjRm4AL95gIG1FhVsrrJNyFEKI3ARfuACMTIymsavR1GUII4bcCMtwnpsdxoKTe12UIIYTfCsxwHxHHkYoGmts6fF2KEEL4pcAM94xY7BoOlknrXQgh3AnIcJ+UEQfA/pI6H1cihBD+KSDDPSc1hqgwK18UVPu6FCGE8EsBGe5hVguLx6fwcV4ZWmtflyOEEH4nIMMd4KxJ6RRUNnKovMHXpQghhN8J2HD/0sQ0AD7OK/NxJUII4X8CNtyzk6MZnx7L2v0S7kII0V3AhjvAjMwEDsiIGSGE6CGgw310SjTFtc20tMtkJiGEcBXQ4T4mJRqtobBSNu4QQghXAR3uo5NjACiolBEzQgjhKqDDfUxKNABHymWFSCGEcBXQ4Z4SE05MuJWCSgl3IYRwFdDhrpQiMymK4hrpcxdCCFcBHe4AidHhVDe2+boMIYTwK4Ef7lFhEu5CCNFNn+GulMpWSq1RSu1VSu1WSt3q5hyllPqrUipfKbVDKTV7aMrtKSk6nOqm1uF6OSGECAg2D85pB36mtd6qlIoDtiilPtRa73E55wJggvm1AHjU/HPIJcaEUdXYhtYapdRwvKQQQvi9PlvuWutirfVW83YdsBfI7HbapcBz2rABSFRKjfR6tW4kRoXT2m6nSbbcE0IIp371uSulcoDTgI3dHsoECl3uF9HzDWBIJEWHAUi/uxBCuPA43JVSscAK4Cda69ruD7v5lh67aCilblJK5SqlcsvKvLOaY6IZ7lWN0u8uhBAOHoW7UioMI9hf0Fq/7uaUIiDb5X4WcLz7SVrrJ7TWc7XWc9PS0gZSbw+J0eEA1EjLXQghnDwZLaOAp4C9Wus/93LaW8C3zFEzC4EarXWxF+vsVZIZ7lUS7kII4eTJaJnFwDeBnUqpbeaxXwGjAbTWjwHvAhcC+UAjcIP3S3VPumWEEKKnPsNda70O933qrudo4BZvFdUfCVFGuNc0SctdCCEcAn6GamSYlZSYcI7IRtlCCOEU8OEOMD0rgR1FNb4uQwgh/EZQhPuMrEQOlNbR2Nru61KEEMIvBEW4z8xKwK5h17Huw++FECI0BUW4n5qZAEDeCQl3IYSAIAn3tNgIwq0Wiqpl0w4hhIAgCXeLRTEyMZLj1c2+LkUIIfxCUIQ7wKiEKI5Ly10IIYAgCvfMJAl3IYRwCJpwH5UYRUltM20ddl+XIoQQPhc04Z6ZGIldw4ka6XcXQoggCvdoAI5WNPq4EiGE8L2gCfeZ2QmEWy18tK/U16UIIYTPBU24x0WGMW9sEk+vP8xT6w77uhwhhPCpoAl3gAibFYC73t7j40qEEMK3gircr5k/GoDRydE+rkQIIXwrqML93KkZXDR9JDbLSfcWEUKIoBdU4Q6QER9JSa0MhxRChLagC/dRiZE0tHZQ1SB7qgohQlfQhfu4tBgADsm2e0KIEBZ04T42NRaAQ2X1Pq5ECCF8J+jCPSspCqWgqEoWERNChK6gC/cwq4WMuEhZIVIIEdKCLtwBY+OOGgl3IUToCspwH5UYJd0yQoiQFpThfkpaLIWVjTS3dfi6FCGE8ImgDPfJI+KwazhQIiNmhBChKWjDHWDviVofVyKEEL4RlOE+JiWGyDALeSfqfF2KEEL4RFCGu9WimJAex/4SCXchRGgKynAHYzJTseynKoQIUUEb7rI6pBAilAVtuKfHR1DX3E5ja7uvSxFCiGEXtOGeERcJQGGlTGYSQoSePsNdKfW0UqpUKbWrl8e/pJSqUUptM79+7f0y+2/BuGQibBb+teGor0sRQohhZ/PgnH8CfwOeO8k5n2qtL/ZKRV6SlRTNzKxE9slYdyFECOqz5a61XgtUDkMtXjcuLYbDsmmHECIEeavPfZFSartS6j2l1DQvPeegjU2Noby+lZqmNl+XIoQQw8ob4b4VGKO1ngk8DLzR24lKqZuUUrlKqdyysjIvvPTJjU01ttyT1rsQItQMOty11rVa63rz9rtAmFIqtZdzn9Baz9Vaz01LSxvsS/dpXJpsuSeECE2DDnel1AillDJvzzefs2Kwz+sNo5OjibBZ2HwkIC8ZCCHEgHkyFPIl4HNgklKqSCn1XaXUzUqpm81TrgR2KaW2A38Flmmt9dCV7Llwm4ULTh3Be7tO+LoUIYQYVn0OhdRaX9PH43/DGCrplyaNiOeNbcd5Zv1hvrUoB6tF+bokIYQYckE7Q9VhREIEAL/97x7+88UxH1cjhBDDI/jDPT7KeVvWmRFChIqgD/espM5wD7cG/Y8rhBBAiIV7Q6tsmC2ECA1BH+5KKcJtxo8pM1WFEKEi6MMdYPMd5wBQK+EuhAgRIRHuCVFhZCZGUdss4S6ECA0hEe4ASTFhVDa0+roMIYQYFiET7ulxkZTWtvi6DCGEGBYhE+4Z8RGU1km4CyFCQ8iEe1pcJBUNLbR32H1dihBCDLmQCfeRCZFoDcU1zb4uRQghhlzIhPuUkfEA7D5e4+NKhBBi6IVQuMcRZlVsL5JwF0IEv5AJ9wiblUkj4tgp4S6ECAEhE+4A0zMT2XlMwl0IEfxCKtzHpERT09RGfYss/SuECG4hFe7pccbGHaW1MmJGCBHcQizcIwFkMpMQIuiFVLhnxBst9xJpuQshglxIhXtmUhThVouMmBFCBL2QCvfocBsLT0nhk/1lvi5FCCGGVEiFO8DMrAQOlTfQ0i5b7gkhglfIhfvEjDg67JrVe0t9XYoQQgyZkAx3gB++sJX80nofVyOEEEMj5MJ9bGqM87aMdxdCBKuQC/dwW+ePXFYv492FEMEp5MId4MXvLQCgTCYzCSGCVEiG+6JxKYTbLDJTVQgRtEIy3JVSjE6O5lCZXFAVQgSnkAx3gGmj4tl9vNbXZQghxJAI2XCfPCKe4ppmfvbqdsrlwqoQIsiEbLiPTo4GYMXWIh74YL+PqxFCCO8K2XDPSopyuad9VocQQgyFkA33bLPlDhAZZvVhJUII4X19hrtS6mmlVKlSalcvjyul1F+VUvlKqR1KqdneL9P7kmPCnbcbZNs9IUSQ8aTl/k/g/JM8fgEwwfy6CXh08GUNjy3/ew42i6KyodXXpQghhFf1Ge5a67VA5UlOuRR4Ths2AIlKqZHeKnAopcRGsHRyOhsPVcqIGSFEUPFGn3smUOhyv8g8FhBuO28idS3trNhS5OtShBDCa7wR7srNMbfDT5RSNymlcpVSuWVl/rEb0uQR8cwZk8SruYVoLaNmhBDBwRvhXgRku9zPAo67O1Fr/YTWeq7Wem5aWpoXXto7Lp4xkoNlDRTXyBLAQojg4I1wfwv4ljlqZiFQo7Uu9sLzDpsJ6cYGHkcqGnxciRBCeIetrxOUUi8BXwJSlVJFwG+AMACt9WPAu8CFQD7QCNwwVMUOlZxUY8z70YpGTj/Fx8UIIYQX9BnuWutr+nhcA7d4rSIfGJkQRWyEja1Hq7hm/mhflyOEEIMWsjNUXVktiq9MG8HK3SfkoqoQIihIuJtmZCVQ29wuuzMJIYKChLvJsXH2yj0lPq5ECCEGT8LdNHmkMWLmsY8P+rgSIYQYPAl3U3pcJDctGcex6iZqGtt8XY4QQgyKhLuLpZPTAfg03z9mzwohxEBJuLuYl5PMqIRI3trmdoKtEEIEDAl3F1aLYm5OMh/sKaGuWbpmhBCBS8K9mykj4wH4+b93+LgSIYQYOAn3bq5daMxQfX/3Cdo67D6uRgghBkbCvZv4yDD+/PWZAByVhcSEEAFKwt2NiRnGmPe8E/U8//kRcpa/Q0t7h2+LGoCXNhWQs/wdmloDr3YhxOD0uXBYKBqfHotFwS0vbnUeO1HTzJiUGB9W1X9/+ygfgIqGFrLCo31cjRBiOEnL3Y3IMCvJMeFdjh2ravJRNUII0X8S7r2YmZXY5f43ntzoo0oGTxa6FCL0SLj34vdfm84zN8zrcuxweQOfH6zwUUUDZ5d0FyLkSJ97L0YkRDIiIZKHls2ipd3O7a/t4Ow/fQzAZ8uXMioxyrcF9kNbh4S7EKFGWu59uHRWJlfOziIxOsx5rK653YcVnVxLewc5y9/hlc0FzmPtdhmvL0SokXD3gMWiWDw+1Xm/1o+XJnCsaPmnD/Y7j7VLy12IkCPh7qHzpmY4b1f78ZLASikA7PbOQJeZtkKEHgl3Dy06JcV5u6qxtctjWmuKa/xjqKTGCPUOl4uo7XZpuQsRaiTcPZQeF+m8fftrO2ht72wNr9h6jEX3fMQXBVW+KK0LR/e6tNyFCG0S7v2w887znLff3VnsvL2jqBqALUd9H+6Oi6eujXXpcxci9Ei490NcZBjrly8lJyWaFzYedR53zGatbGjt7VuHjaPl3mF37ZaRlrsQoUbCvZ8yE6M4fXwqB8s6V4yMCTemC/hDuHe23F27ZaTlLkSokXAfgFEJkVQ2tNLcZqy26FgxcqUfrAHvaLG7hrt0ywgReiTcB2BEgjE79URNMwBNZshXNbZxqMy3a8A7Rsl02DXmqMgBdcvsLa5lTV6pN0sTQgwjCfcBGJVgjJy5442d7DpWQ1NrZ3jmldS5/Z73d53g3vf2ebWOG5/dzFcfXtflmKOV7npBdSDdMhc89Ck3PLN5UPUJIXxHwn0AZmQbK0auz6/ggQ/yaGrrICEqDKtFsf+E+3C/+V9beOyTg16tY9XeUnYeq+lyzN0iYe0yFFKIkCPhPgCxETaumW/stbomr4yXNhVgtSjGpcb02nJ3GOqgdTdhqU0mMQkRciTcB+iey6dz12WnOu9XNrQycUQceb203B1qmoZ26YION0E+mDcUu7wxCBGQJNwHYfborht6TMqIo6CykcbW3leNrBridWnch/vAA9pxsVgIEVgk3Adhyoh4fnT2eACU6txY+0BJfa/fU93o/bHwrq1rd+HeNohJTBLuQgQm2axjECwWxf98ZRLfPj0HpTrXec8rqWNmdqLb73FMdKpqaKWtw056fKTb8/qjqa2DmAjjn9LrLfdWCXchApFHLXel1PlKqTylVL5Sarmbx69XSpUppbaZXzd6v1T/lRYXQWpsBKOTo4kMs7gdMZNkbvZxvNpYPXLJ/WuY/4fVXnn9BpduINdwdwyccUyyGghpuQsRmPoMd6WUFXgEuACYClyjlJrq5tRXtNazzK8nvVxnQLBaFBPS43hy3WEu//t65wxWwNmyLqwywt3RyvfGBUvX1rXraJlW80Jq4yBa34P5XuEdK3efYN2Bcl+XIQKMJy33+UC+1vqQ1roVeBm4dGjLClw3njkWgK0F1ew8VsPWgiq01s4lggsrG7ucX1LXPOjXbGjpDOAON0v9DqZrRbplfO/7z2/huqc2+roMEWA8CfdMoNDlfpF5rLsrlFI7lFKvKaWyvVJdALp0Via3fnkCAFc99jmX//0zVmw95mzFO1ruDkfKG3s8R3/11i3T1u6Nlrv/7hcrhOidJ+Gu3Bzr3pfwXyBHaz0DWAU86/aJlLpJKZWrlMotKyvrX6UB5CfnTOAMlz1XD5TU0WIGbVFlI9plFmmpF1ruNS7DK113YGr2QrhX1Pt+pUshRP95Eu5FgGtLPAs47nqC1rpCa91i3v0HMMfdE2mtn9Baz9Vaz01LSxtIvQFBKcXz353vvF/b3E5Lu52YcCt1Le3UNLURa/bB7zleO+jXc50Y1eEy7NHRim8ewEXR+EijvpLawb/5CCGGnyfhvhmYoJQaq5QKB5YBb7meoJQa6XL3EmCv90oMTEopnv2OEfAvbSoAYMrIeAAuf/Qz58ehx9ce4p0dxe6eok8RNuOfr7pLuPc8byBdKxaLUWFpXUsfZwoh/FGf4a61bgd+BKzECO1Xtda7lVK/U0pdYp72Y6XUbqXUduDHwPVDVXAgOWtiGne7LFHwq4umoBQcKmugrqUzcN/cdmxAz+8YgdNby91hIN0yjrHx0nIXIjB5NIlJa/0u8G63Y792uf1L4JfeLS04XD0vm9LaZk4fn8rs0Un890dncLG5TO/M7ESqG1v5OK+MwspGspKMdeKVcneZoydH332Ny6xXdwuHDWSsumMYZYm03IUISDJDdYiFWS3cdt4k5/1T0mKdt78yLYOUmHB+sWInZ963xnl8/90XEG7ru8fMEeSu69W4Gzc/kOGMjmGUZdJyFyIgydoywywq3OpccCzCZuXcqSN6nFNW71lr2XHB9EBp51o23VvuidFh1DS1dRmh48nzOk4vrWuRlSGFCEAS7j5w3jQj0I+UN5AcE87Pzp3Y5XHH9n19cYZ7SZ1zREz3tWVGJ0fT0m7v11LDjlZ7RnwE7XZNhR9s/B2q5I1VDJSEuw9cM380i8encO1CY8OP9PiILo+XetgV0mHXZCZG0W7XFJmTo7qHe3ZSNAAn+tG94gj3ySOM0T3/3lJ4stPFEGpzM7RVCE9IuPtAQlQYL9y40BmeKTFdw33V3lKP/iO32zXZycZFWMeCZN27ZbKTjXAv9vDTAHTuuXr2pDQyE6PY1W0rPzF8XPe/dSxh4Y/aOuwUVAx+trXwHgl3PzAioeuyvyu2FvFq7slby46P66PN8HaEe/c3hVPSYgBj+KWnHKtIRoRZyUyKolxmqfqM6y5ag1ndc6jd9fYelty/hgoPrxeJoSfh7gemjYrnpiXj+PXFU/nWojGAMXN17f4yynoZiuhooY9KjMKiOsO9oaWdyLDOf9bMpCgyE6PYcrTS43ocLcQIm4XU2HD5D+tDrS7h7s8t99V7S4HO1U6F78lQSD+glOJXF04BjBb51oIqnt9wlOc3HGXZvGzuvWJGj+9xtNAjbFYy4iM5Vm10u9Q2txEfGUaYtYO65nbCrRbm5SSx/mAFWuuTjqHfW1zL+PRY5zo44TYLKTERVDRU9Po9drtmw6EK5o1NJswqbQVvc+2WafHjcHf8PobaEtGVDa3ER9qw+eHvvv9VFOIsFsWZEzrX3emtr9yxQJjNohiVGOVsudc2tRMfFcZUc6mDhtYO5uYkU1bXQkFl732inx0s54KHPuW5z4/S0uZouVtJiQ2nurGt11bj79/dyzee3MjHed5dCO6zg+XsLzn5ZuOhwLVbxp9bxY7fx4YQWkW0pqmN2Xd9yAMf7vd1KW5JuPuhi6Z3LtXjCO3uOswWncUR7jVmuDe3ERdp474rZ7B0cjpzxiQxLycZgM1Hqnp9zQ92lwDG8MzWDrPP3WYhyxxtU1jl/o1hZ5FxsdXbyxR84x8bOe8va736nIGozSXcK/14SKqj5V7vx29A3rbbHGjwWb5/bqQi4e6HTs1M4A9fm868nCQOlNbz1LrDgLEA2OOfHKSivqVLyz07yWi5t7R3UNtkdMuMSYnh6evnERthY0J6LAlRYXx2sPdfwmLzzaGsrsXZcg+3WZiQbsyo7W3Tb5vV6Obx5+AJZK3tnd0yFQ3+e+3DEe6uayYFu13HjXCfmBHn40rck3D3U99YMJq/X2usnHzf+/sorGzkkTX53PPePn7wwlZni85qUczISqStQ7PrWC21zUa3jCuLRXHh9BG8vvUYH+w+0eWx7YXV2O3aOXEqv6ze2bcbYbNwSnosFgUbDrnvd3d010i4921/SV2/l3h2bbn789r6ju6jhhAKd8cItKhwq48rcU/C3Y+lxUXwxDfn0NJu58z71vDImoMAbDpc6RydYLUo5oxJAuDbT2/iWHWTcy12V7d/ZTLxkTb++dkR57FthdVc+sh6Hvgwz9m3n19a7xyhE26zEBth45KZo/h3bqHbsff15n9mCfe+nfeXtVz410/79T3tLpOY/LXlXt3YSoN5ITWUumUOlRvhPpD9EoaDhLufO2dKhnPbPoC/XD2T1NgI7np7D2CEe1qcMQmqvqWd1nY7Y1NjejxPUkw431gwhk2HKymsbKStw856s6/w9a3HKKtvYb7ZN7/piDFsMsJmtEjOmpRGQ2uH2wucjot8QxU8ob7Nn6OLDKC42j8XcdtWWO28XdkYOm/yjklbTW3+OYpJwt3PWSyKn547kZdvWsgNi3O4ZGYmy+ZlO5fxtZmbarx5y2Ln9zhGynR33cLRaODM+9Yw4Y73uH9lHmCMyNEazpxgbA24t9joOnBsBjIvJxmLgrvf2UNbh53imiZnK94xOqI/M2D7o7wudMLCnRazuyM63MrBcs8nog0nx/DHcJuFLSe5aB9s6pqN9Zqk5S4GZeG4FH7z1WlYLYofLR3vXHYgLtLoX5+ZnchrNy/inCnpzDJXnewuKymaby4c02U54fS4zqUPTs1KAGD38a7hnpUUze+/Np31+RXcvzKPRfd8xAsbj6K1dn4ML6pq8toiV67dP56ukBlI+vP35Gi5Tx0Zz6HS+n6t7jlcHDNnl0xIZVtRdUisgaO1ptEMdQl34TWRYVbev3UJK35wOksnpzuPz81J5slvzyM6vPe5aXdeMo28u85n7+/O549XTOeV7y9yPjYqIcq5YQh0dssAXD03m7hIG0+sPQTAFwXVtLTbabdrRiZE0tpuZ2W3i7UD5XoRsTwIw70/49UdM1SnjIynrqW91xnLvuS4qD5lZDyt7XbnyKvhdv0zm7j5+S3D8lrNbXbnstgS7sKrYiJszBmThNXi2a5NrpRSRIVbuXreaMamxvBjs08/KymK924903lehMsyBhaL4tcXTyUlJhwwQveo2ed48QxjXP4Tnx4a0M9S29zWpTXrOuXeH8Osu9K6/nVJPb72IIfK3A8t7a7FDI6po4yutnwPv28wCisb+1zbyJUj3B1DAo/6aAGxj/PKeN8LDYzmtg5ylr/Dsy6DD7pznazVLH3uwl/ddu5E9t99ATERNmc3D0B4tynVV83NZtMd53D13Gw+PVDO2zuOO4//9JyJbCus5ouCqn51O5yoaWbGnR/w7OdHnMdcZ8P6e8s9v7SO+b9fzZP9eGP7+8cHuf21HR6d69pyBzjYjwXgBmrZExu4/bUdHg9rdAydHW/OiTjZTOhA4Ni/4NGPD/Z47M1txzhUVt9ldzNpuQu/5toPv/InS/jfi6ZgcfOpwGpRnD3ZWB7h4Y/yARiXGsN50zLQGr729894YVPBSV/rlc0FbDlqXHhbk1dq/tm5fIFrt0xJbc9wP1BSxx/e3Tvgvl2tNZf+bR3/XH94QN/7/IajzsXUHD/Hnz7I69fzxLoZruqOo899THI00eFWj1v8g3HMnBXt6Rur4w0o0+zSKw+AT1sn47iO5Jig53CipplbX97GD/611dlyjwqzDmiP4uEg4S56mDQijhvPHNfr4+dNHcEvL5gMwIKxydisFiaP6Jyll3uk6wqU+0vqeGjVAWqa2vjJy1/wixU7ueLRz1h870esO2AMx4yL6Aw715Z77pHKHp8EHlx1gCfWHuLDPQP7CJ5XUsf2ohru/O8et4+/s6OY657c6PbiZVFVE//3xi6+b/btbis0Zik2t9kpPEmLtfvP4GlnmiM4I8IsjEuL8UrLvbmtw6PWpsfhbv57xYbbSIgKC/iL4NXmcM7un1wdQ4c12jlCKD0+gprG/m1jOVwk3EW/WSyK7591Cu/deiaPXmfMolVK8cnPvwTAm9uO8+GeEuf5P3xhK39ZtZ/T71nNG9uOO48fq27inZ3FztsOri33A6X1PLj6QJfXTzb7/TcdNlrNNY1t/dpQ5IsCY1x2amyE28dveXEr6/LL3YaUo5WWe7QKrTUf55U6L0JvL6rucb6DI6S/v2Qc83KSqGz0bNtD51IQVgunpMWS74XF1Bbds5rF937EwbJ6Vu8t6fU8T693tLbbCbMqLBZFamy433el9cWxJWX3lnutOfQx3GahscX4PZgzJom6lnaO+OFGJRLuYsCmjIx3Bi3AmJQY7r18OgDfey6Xe97by1cfXke+uYF3Q2sHETYLH/x0Cd87c2yX59pWWO2c7dp9adtn1nXtPnH85ztcbjzvD17YwsUPr+vSD3oyjgt+fa3SWlhpvOForVl3oJzmto4uI12qG9sormnm2gVjsFnUSZcWcLSUM+IjGZUYRZWHM3pbOzqwWhQ2q4VTRyVwvKZ50OFZ1dhGRUMrX314Hd99NrdL95Zj7DZ4vpdva7vd2cpNjY3odW5CeX1Lry3c5rYOXt1ciNaat3ccH1Q/tutKmgNRbf5+dV/C2tFab2rtcE6uO/0UY27I9sLe39h9RcJdeNXV87J545bFLBqXwuOfHGLnsRpGJURy3tQM0uMieOmmhUzMiOOOi6Zy+exMwOi3BLj2yY1A5xrm/3fxVE7NNIYAPvnpIR5Zk883n9roDB1HF0Wu2e/9+SHPVucrqDS+r6K+tUcQuAZdkbkS5js7i7nuqY38a8NR5xsQwJEK43lGJEQwPj3WOfnLHed6PWEWUmMjKKlt9ijAWtrszvkGM7ON+Qtvunz6GQxHWLl2J7nu2LXGw2WcW9rtzms2o5Oj2XSkkk2Hu3bNHS5vYO7dq3ju86Nun+Ovqw9w+4odPLjqAD968Qvu+M+ufv0srm8aDS2D6wOvdbbcu4e78W9f39JOrfkmP3t0ItHO8ELCAAAR2ElEQVTh1i6zdP2FhLvwKqUUs7ITeeaGefz0nIk8cNVMPv3FUp741lw23XEOs0cnOc89e5IxRv87Z+SQkxLN9sJqjlU3sWafcZF18og4HjO7fR74YD/3r8zj0wPlzuURCiob2V5YTYa5wfjyFTs5WtF3n7RjNEe7XfcYOlflMn1+u9mf7lirvrqxrcvaKY4+2ISoMKaMjHdO/nLH8aki0mbly1PSafFwXkBrR2dwzhmTxOmnpPDgqv0Dbr27W87BdVkJxxvWkolpfH6wwu0b0P6SOufPDmbL3azRMYHu649/3uV7HGPfX97sfoilY1E0x3lbC/o309V1+Gz9IJescAR39/EEjjfDqoY25/DXjPhITs1MOGmXnK9IuIshERlm5dZzJnDFnKxex+JfPGMk635xNredO4nnvrMAi4LF937EQ2Yfe7i5nvz9V85w9nVPMsdSXzZrFHGRNq57aiOFlU1YLYrSuhbOuv/jHv3ve47XkrP8HfaX1KG15mhFI9cuGE1WUhSvdAsb1wXQnl5/mE8PlDmPlde3UN/S2W3huK6QEBXGrOxESutaeHPbMbc/q2NUUEZ8JAvHppAYHcZbHrTAXVvuVovizkum0dpu5863dpNfWtfv7gB3XSYHSuv5ZH8Zy1fscIbsRdNH0NphZ6ebaxk/+NcWrn1yI4fN5RBaO+zOCW8XTx/lPM/12onjTbG3CU5hNuN35NXcIqD/+wO4jjV3XBDtsOsBbdrdZL45dO/mc9xv7bCTe6SKyDAL0eFWZmUnsvt4rd9tgyjhLnxGKUVWUjRWi2J0SjS/vGAKY1KinY87LnhedlomX5qUxrRR8bz+w9N59NrZ3HP5DP7zw8XO1tSj187m63OzALj44XU89/kRZ//xv7cYAf7OjmKO1zRT19zO2NQYLpuVyfr8ckpdgsQRbv9v6XgAHl6d71w35+XNhawyV+OckB7LdnOjkoSocK6ZP5rs5Cj+vuag2yGa6w6UMy4thsXjU7BYFF+ZOoLV+0p5a/vJA9615Q7GRKHrF+fw7s5izvnzWi59ZD15J+o83jy7qLrRWb/D/pI67nxrNy9vLuQN883pDHM3MHddTY4gXbn7BFpr3t1Z7GzlJkSHOT9tubbuHZ+IqnsZWWKzuO/f9pTrz7+32Pgk8vt39rLk/jX9/pTjWOGy+65SrjV9tK+U1NgIlFLMzEqktd1+0m45X5BwF37je0vG8cnPz+av15zGXZdOc65uGWa18M8b5vPOj88kJsLGBdNHEhVuZXx6LJ/efjZPfXsu507N4L4rZ/LAVTNRCn795m7OvG8Nf3x/Hy9sNMbdP7T6AIvv/QiAnJQYvjY7E7vGGWjQubrlRTNGcs/l09l0pLLLf1pHa/2XF052HkuICiPcZuEb88eQV1LHM27Gz+eX1TNlZLxzD9vfXjqNySPiuPfdvb2Gz9r9Zby1/TjxkV3X57/1yxNYMrFzK8avPLiWX3g4KWr/CSP47rrsVOexrQVVRJrXPXYU1RAXYWNUQiRxETbyS+t59OODfG7uwftFQZWzT3rdgXK2FlTR0m7vMlpk6eR0UmLCue3V7c75AJUNnZ94Hvig57Z07rqLbnw21+MLq66rZ246XEFpbTMvbzb+3fu7mqajhV5S00JzWwcdds097+3lYFk9kzLinLO0U8zGx7ycJPN1Pd+EfjhIuAu/c8nMUXxzUY5H545KjOLLUzKcoXnFnCzW/vxs7r7sVEYnR/Poxwd7fFyel5PEWZPSOCUtltNGJ/KHd/eRs/ydLksqjEqMYtm8bDITjWGOrmOex6REO0dJgBHuADefNY5Z2Yk8siafLUcruevtPXzzqY3c+OxmjlY0dmktR4ZZ+fXFUzle08zcu1extaDK2aLVWqO15oWNR+mwa37z1Wld6o8Ot/HM9fNY/bOznLNC39h23KMJTnkl9SRGh7FgbDIrfrCI/71oCoWVTV3ewOKjwlBKMT4jluc+P8of39/HNf/YwI9f3sbX/v6Zc7elTUcqOVzes9sj3GbhmvmjqWxoZc7dqzj7Tx+zrbCzD/31rUU9vqfazdDQVXtLTrp7mCvXlvuruUXM/8NqZ0v7RD+7eBxvNK0ddn739h72Ftfy+CeH2H28lthIGxea22COTzP+7tPjIxmbGsPGw71vJO8Lnk2TEyKAZCdHc93CMVw+O5NL/7aeqaPiefDqWby8uZCZWYnOdVoA/nTVTL78wCcAzL17lfO4o7W8YFwyr289xqs3L+K9XcWU1rZw1ZwsIsOsvHLTQmxW5ew2UUrx4NWz+Prjn3PFo10vKAKcf+qILvdPH5/K8gsmc+97+7j8758B8PA1p7FqbwlldS3sO1HH5adlMn9sco/nUkpxSlosr//wdD7Lr+Bnr25j2RMbWPmTJSS5DE/tbn9JHRMz4lBKMWdMMjOzEnn044NUNLRy2uhEviioxtFDsnRSunNOAMB/XbqQFo9PYX1+Bf/z7+0A/OL8yV1e5yfnTCAjIZL739/H4fIGDpc3MHVkPNfMz+b/3tzNrS9/QVuHndmjk7jxzHGU1bewcFwyGw51bf3+3xu7UZcpznZZIO/GZzczPTORW8/p3OfA0VW0YGwyG7u1oE/0cyGzxtYOspKiKKpq4sWNBV1GVIVbLfzsvInERNj4zhk5zuMLxiazYmsRx6ubGJUY5eZZh5/y1cyquXPn6tzcXJ+8thCu3t9VzJ8/3M+hsgba7Zqlk9N5+vp5gDHue9exWhadkuLx81U1tHL/B3lsPFThHK756LWzucBl43NXmw5X9hhdAqAUvHLTIrfh3t2Dq/bz4CrjQvS4tBiWTEgjLtLGJ/vLOFzewG3nTqSoqomn1h3mmwvHdOmWKaho5N9bClk4LoVrn9xIfKSNHXd+hZqmNu57fx+TR8Rx1sR0lty/xvk9b/1oMZf8bb3z/pF7L3JbV0ltMxc/vI6axjbuv8rYtH3pA590mSB181mn8NgnB7n+9BznTmHTRnUdffSbr07l2gVjqGtuY475JvzAVTO5Yo5xnWXl7hN8//kt3HfFDG5f0bWLymZRrPjB6c6hpH254tHPiAyzsD7faIlHh1udnwLOnzaCx745p8f3fLK/jG8/vQmAc6dmcNelp5IeF+F2CY/BUkpt0VrP7fM8CXchjK6Q1g47tU3thFstJESH9f1NfbDbNR/tK8VqVc5hn72pbGilrrmNtfvLaGjt4GhFI6ekxZx0GYjuXtpUwCNr8mltt1N6ktmlvb3RaK15aPUBRidHc/nsrB6P/+K1HRypaOCfN8wnKtzKvhO1nP/gp1w8YyR/+8Zsj+tsbbdTVt/CXz7czzs7ip0joR5aNguAz/Ir+OOVM+iwa77++OfO9XvcWTQuha+dlsnxmiYeWn2AXXd+hWc/P8LSyenkl9ajUNzy4lYA3vnxGUwbldBnfec/uJbs5GgunD6Cn76y3Xn8xe8tYFxqLCMSIt1+34sbC/jVf3YCEBNupbXDzvILpnDV3Kwe100GQ8JdiBCltWZbYTXl9a3Myk6ksKqRptYORidHk50c3fcT9EPeiTrGpEQ7L8j216Gyej7cU8L49FjOmpjWY+JQfUs7972/jwnpsTy+9hBFVU1EhVl5+vp5XPOPDV3OnZgRywc/PavHa7y+tYjbXjVC+qFls1i7v5yjFQ3cdt5EFo1LoaqxrctM67PuX8Os7EQeWnYa2wqruewR4xNKb59OXBVVNXKgpJ6XNxewcnfn0g7hVgvL5mdz6axRzBnT9yexk5FwF0IElbYOO0crGoiPDCM9PpLqxlb+88UxfvvfPXx5cjq3njOBGVnuu17+uvoAf/6w5ygdq0XRYddYLYobTs9BA//acJTLZ2dxz+XT6bBrrnzsM65bMMbZBeSpfSdqufn5LVQ1tlHX3IZjhOy8nCS+e8ZYzj/VfTddXyTchRDCRUNLO795azeLxqWQEBXGjc/lEhlmcbvZxmPXzelxAXwwqhtbaWm388KGo7y1/ThXzc3mlrPHD+i5vBruSqnzgYcAK/Ck1vrebo9HAM8Bc4AK4Gqt9ZGTPaeEuxDC17TWtNs1WhtrDm06XIVda65dMNo5vHaoXnegz+9puPc5FFIpZQUeAc4FioDNSqm3tNaui2F/F6jSWo9XSi0D/ghcPaDKhRBimCilCDOX9h2fHsf49Lg+vsN7rzvUPJnENB/I11of0lq3Ai8Dl3Y751LgWfP2a8CX1XBUL4QQwi1Pwj0TcF1dqcg85vYcrXU7UAP0GBislLpJKZWrlMotK/NsOVEhhBD950m4u2uBd++o9+QctNZPaK3naq3npqWlufkWIYQQ3uBJuBcB2S73s4DuS9k5z1FK2YAEwL9W0RFCiBDiSbhvBiYopcYqpcKBZcBb3c55C/i2eftK4CPtjzvGCiFEiOhztIzWul0p9SNgJcZQyKe11ruVUr8DcrXWbwFPAc8rpfIxWuzLhrJoIYQQJ+fRqpBa63eBd7sd+7XL7WbgKu+WJoQQYqBkPXchhAhCPlt+QClVBrjfCr1vqYBnq/j7B6l36ARSrRBY9QZSrRBY9Q6m1jFa6z6HG/os3AdDKZXryfRbfyH1Dp1AqhUCq95AqhUCq97hqFW6ZYQQIghJuAshRBAK1HB/wtcF9JPUO3QCqVYIrHoDqVYIrHqHvNaA7HMXQghxcoHachdCCHESARfuSqnzlVJ5Sql8pdRyX9cDoJR6WilVqpTa5XIsWSn1oVLqgPlnknlcKaX+ata/Qynl+c7C3qk1Wym1Rim1Vym1Wyl1q7/Wq5SKVEptUkptN2v9rXl8rFJqo1nrK+ayGCilIsz7+ebjOcNVa7e6rUqpL5RSb/t7vUqpI0qpnUqpbUqpXPOY3/0umK+fqJR6TSm1z/z9XeTHtU4y/04dX7VKqZ8Ma71a64D5wlj+4CAwDggHtgNT/aCuJcBsYJfLsfuA5ebt5cAfzdsXAu9hrKS5ENg4zLWOBGabt+OA/cBUf6zXfM1Y83YYsNGs4VVgmXn8MeAH5u0fAo+Zt5cBr/jo9+E24EXgbfO+39YLHAFSux3zu98F8/WfBW40b4cDif5aa7e6rcAJYMxw1uuTH3YQf0mLgJUu938J/NLXdZm15HQL9zxgpHl7JJBn3n4cuMbdeT6q+02MXbb8ul4gGtgKLMCY/GHr/juBsf7RIvO2zTxPDXOdWcBqYCnwtvmf1Z/rdRfufve7AMQDh7v//fhjrW5qPw9YP9z1Blq3jCcbh/iLDK11MYD5Z7p53G9+BrMb4DSMFrFf1mt2cWwDSoEPMT65VWtjU5ju9Xi0acwQexC4HXDsupyCf9ergQ+UUluUUjeZx/zxd2EcUAY8Y3Z5PamUivHTWrtbBrxk3h62egMt3D3aFMTP+cXPoJSKBVYAP9Fa157sVDfHhq1erXWH1noWRot4PjDlJPX4tFal1MVAqdZ6i+thN6f6Rb2mxVrr2cAFwC1KqSUnOdeX9dowuj4f1VqfBjRgdGv0xh/+bjGvr1wC/LuvU90cG1S9gRbunmwc4i9KlFIjAcw/S83jPv8ZlFJhGMH+gtb6dfOw39YLoLWuBj7G6I9MVMamMN3r8fWmMYuBS5RSRzD2Gl6K0ZL313rRWh83/ywF/oPxBuqPvwtFQJHWeqN5/zWMsPfHWl1dAGzVWpeY94et3kALd082DvEXrhuYfBujb9tx/Fvm1fGFQI3jY9pwUEopjPX392qt/+zP9Sql0pRSiebtKOAcYC+wBmNTGHe1+mzTGK31L7XWWVrrHIzfzY+01tf6a71KqRilVJzjNkbf8C788HdBa30CKFRKTTIPfRnY44+1dnMNnV0yjrqGp15fXGAY5MWJCzFGeBwE7vB1PWZNLwHFQBvGO/B3MfpOVwMHzD+TzXMV8IhZ/05g7jDXegbGx70dwDbz60J/rBeYAXxh1roL+LV5fBywCcjH+LgbYR6PNO/nm4+P8+HvxJfoHC3jl/WadW03v3Y7/j/54++C+fqzgFzz9+ENIMlfazVriAYqgASXY8NWr8xQFUKIIBRo3TJCCCE8IOEuhBBBSMJdCCGCkIS7EEIEIQl3IYQIQhLuQggRhCTchRAiCEm4CyFEEPr/OSzcYyjFs4cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3259, 10)\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "9\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "5\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "7\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "5\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "9\n",
      "1\n",
      "1\n",
      "7\n",
      "1\n",
      "1\n",
      "9\n",
      "1\n",
      "7\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "7\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "9\n",
      "1\n",
      "1\n",
      "1\n",
      "5\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "7\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "9\n",
      "9\n",
      "1\n",
      "1\n",
      "5\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "7\n",
      "1\n",
      "5\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "7\n",
      "1\n",
      "9\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "5\n",
      "1\n",
      "1\n",
      "1\n",
      "5\n",
      "9\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "5\n",
      "1\n",
      "1\n",
      "7\n",
      "1\n",
      "9\n",
      "1\n",
      "9\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "5\n",
      "9\n",
      "9\n",
      "1\n",
      "9\n",
      "7\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "9\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "5\n",
      "9\n",
      "5\n",
      "9\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "9\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "6\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "7\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "9\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "7\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "7\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "7\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "7\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "9\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "7\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "2\n",
      "2\n",
      "7\n",
      "2\n",
      "7\n",
      "4\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "8\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "8\n",
      "4\n",
      "4\n",
      "2\n",
      "6\n",
      "1\n",
      "8\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "7\n",
      "2\n",
      "7\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "6\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "9\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "7\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "6\n",
      "7\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "9\n",
      "3\n",
      "7\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "8\n",
      "9\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "8\n",
      "3\n",
      "7\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "8\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "8\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "8\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "8\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "9\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "6\n",
      "3\n",
      "5\n",
      "8\n",
      "3\n",
      "3\n",
      "7\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "9\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "9\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "9\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "8\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "7\n",
      "5\n",
      "3\n",
      "3\n",
      "8\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "8\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "7\n",
      "3\n",
      "7\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "8\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "8\n",
      "8\n",
      "8\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "8\n",
      "3\n",
      "8\n",
      "3\n",
      "8\n",
      "9\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "8\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "8\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "8\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "8\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "5\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "5\n",
      "2\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "8\n",
      "4\n",
      "2\n",
      "4\n",
      "5\n",
      "2\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "7\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "7\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "5\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "7\n",
      "4\n",
      "4\n",
      "4\n",
      "9\n",
      "4\n",
      "4\n",
      "2\n",
      "8\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "7\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "9\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "9\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "8\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "7\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "4\n",
      "4\n",
      "5\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "5\n",
      "7\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "7\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "1\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "9\n",
      "5\n",
      "5\n",
      "9\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "5\n",
      "7\n",
      "7\n",
      "5\n",
      "1\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "9\n",
      "5\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "1\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "9\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "5\n",
      "7\n",
      "5\n",
      "7\n",
      "5\n",
      "5\n",
      "4\n",
      "2\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "2\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "8\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "2\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "8\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "9\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "9\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "2\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "9\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "8\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "4\n",
      "5\n",
      "5\n",
      "8\n",
      "8\n",
      "5\n",
      "9\n",
      "5\n",
      "5\n",
      "9\n",
      "5\n",
      "5\n",
      "8\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "8\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "9\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "9\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "5\n",
      "5\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "2\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "8\n",
      "3\n",
      "6\n",
      "8\n",
      "6\n",
      "8\n",
      "6\n",
      "8\n",
      "6\n",
      "9\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "8\n",
      "8\n",
      "6\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "9\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "1\n",
      "3\n",
      "6\n",
      "6\n",
      "3\n",
      "5\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "2\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "5\n",
      "6\n",
      "6\n",
      "2\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "5\n",
      "4\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "9\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "8\n",
      "2\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "8\n",
      "5\n",
      "6\n",
      "6\n",
      "2\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "2\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "2\n",
      "6\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "9\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "2\n",
      "2\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "9\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "9\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "4\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "5\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "5\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "2\n",
      "7\n",
      "3\n",
      "7\n",
      "7\n",
      "7\n",
      "9\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "4\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "4\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "5\n",
      "1\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "1\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "2\n",
      "1\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "2\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "2\n",
      "7\n",
      "2\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "1\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "5\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "6\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "5\n",
      "7\n",
      "7\n",
      "1\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "1\n",
      "7\n",
      "5\n",
      "7\n",
      "4\n",
      "7\n",
      "2\n",
      "8\n",
      "7\n",
      "8\n",
      "3\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "5\n",
      "4\n",
      "8\n",
      "7\n",
      "7\n",
      "3\n",
      "7\n",
      "3\n",
      "9\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "2\n",
      "7\n",
      "4\n",
      "7\n",
      "8\n",
      "7\n",
      "8\n",
      "7\n",
      "2\n",
      "2\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "2\n",
      "7\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "4\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "4\n",
      "8\n",
      "8\n",
      "6\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "8\n",
      "7\n",
      "8\n",
      "8\n",
      "7\n",
      "3\n",
      "8\n",
      "6\n",
      "6\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "8\n",
      "3\n",
      "8\n",
      "3\n",
      "8\n",
      "6\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "3\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "8\n",
      "8\n",
      "3\n",
      "8\n",
      "7\n",
      "2\n",
      "8\n",
      "8\n",
      "8\n",
      "6\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "5\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "6\n",
      "8\n",
      "5\n",
      "7\n",
      "4\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "8\n",
      "8\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "3\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "3\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "6\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "3\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "6\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "3\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "3\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "5\n",
      "2\n",
      "8\n",
      "8\n",
      "6\n",
      "8\n",
      "8\n",
      "6\n",
      "8\n",
      "8\n",
      "7\n",
      "8\n",
      "6\n",
      "8\n",
      "3\n",
      "8\n",
      "6\n",
      "8\n",
      "6\n",
      "8\n",
      "5\n",
      "8\n",
      "8\n",
      "8\n",
      "3\n",
      "8\n",
      "8\n",
      "7\n",
      "6\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "3\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "3\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "8\n",
      "3\n",
      "4\n",
      "8\n",
      "8\n",
      "2\n",
      "5\n",
      "8\n",
      "1\n",
      "8\n",
      "7\n",
      "2\n",
      "8\n",
      "8\n",
      "6\n",
      "5\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "8\n",
      "7\n",
      "2\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "2\n",
      "6\n",
      "1\n",
      "5\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "8\n",
      "4\n",
      "8\n",
      "8\n",
      "5\n",
      "8\n",
      "8\n",
      "8\n",
      "3\n",
      "8\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "5\n",
      "8\n",
      "8\n",
      "6\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "3\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "6\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "6\n",
      "8\n",
      "8\n",
      "8\n",
      "6\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "8\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "8\n",
      "8\n",
      "6\n",
      "8\n",
      "9\n",
      "1\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "9\n",
      "1\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "1\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "1\n",
      "1\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "5\n",
      "9\n",
      "9\n",
      "7\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "1\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "9\n",
      "7\n",
      "5\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "3\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "5\n",
      "9\n",
      "9\n",
      "1\n",
      "9\n",
      "9\n",
      "1\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "9\n",
      "9\n",
      "1\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "3\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "6\n",
      "9\n",
      "9\n",
      "9\n",
      "1\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "3\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "5\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "2\n",
      "7\n",
      "9\n",
      "3\n",
      "5\n",
      "9\n",
      "1\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "1\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "4\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "3\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "5\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "3\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "5\n",
      "7\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "9\n",
      "9\n",
      "9\n",
      "1\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(x_test)\n",
    "print(result.shape)\n",
    "for i in range(len(result)):\n",
    "    print(np.argmax(result[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
